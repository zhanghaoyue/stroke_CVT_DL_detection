{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "663dd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, auc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision.ops import box_iou\n",
    "from torchvision.ops import nms\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "from ensemble_boxes import non_maximum_weighted\n",
    "\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d688cfbd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e74d83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_list = [ 557,  600,  614,  547,  503]\n",
    "case_list = [1193, 1185, 1192, 1175, 1147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "58425538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MCS_NL23_bs16_iou03_size448',\n",
      " 'MCS_NL3_bs16_iou03_size448',\n",
      " 'MCSdv0123_bs16_iou03_size448',\n",
      " 'MCSdv123_bs16_iou03_size448',\n",
      " 'MCSdv23_bs16_iou03_size448',\n",
      " 'MCSdv23_bs16_iou03_size896',\n",
      " 'MCSdv3_bs16_iou03_size448',\n",
      " 'MC_CO_dv0123_bs16_iou03_size448',\n",
      " 'MC_CO_dv123_bs16_iou03_size448',\n",
      " 'MC_CO_dv123_bs16_iou03_size896',\n",
      " 'MC_CO_dv23_bs16_iou03_size448',\n",
      " 'MC_CO_dv23_bs16_iou03_size896',\n",
      " 'MC_CO_dv3_bs16_iou03_size448',\n",
      " 'MC_CO_dv3_bs16_iou03_size896',\n",
      " 'MC_SE_dv23_bs16_iou03_size896',\n",
      " 'MC_SE_dv3_bs16_iou03_size896',\n",
      " 'MCpre_bs16_iou03_size672',\n",
      " 'MCpre_bs16_iou03_size896',\n",
      " 'MP_b012_CO_dv0123_bs16_iou03_size896',\n",
      " 'mask_rcnn_1',\n",
      " 'mask_rcnn_FLAIR',\n",
      " 'mask_rcnn_T1',\n",
      " 'mask_rcnn_T1T2',\n",
      " 'mask_rcnn_T2',\n",
      " 'mask_rcnn_T2FLAIR',\n",
      " 'mrDS_bs16_iou03_size892',\n",
      " 'mrSAdv23_bs16_iou03_size448',\n",
      " 'mrSAdv23_bs16_iou03_size896',\n",
      " 'mrSAdv3_bs16_iou03_size448',\n",
      " 'mrSAdv3_bs16_iou03_size896',\n",
      " 'mr_bs16_iou03_size448_base1',\n",
      " 'mr_bs16_iou03_size448_base2',\n",
      " 'mr_bs16_iou03_size896',\n",
      " 'mr_bs16_iou03_size896_base2',\n",
      " 'mrcls',\n",
      " 'mrcls3w01_bs16_iou03_size448',\n",
      " 'mrcls_BCE_p_w01_bs16_iou03_size448',\n",
      " 'mrcls_BCE_s_w01_bs16_iou03_size448',\n",
      " 'mrcls_CE_p_w01_bs16_iou03_size448',\n",
      " 'mrcls_CE_s_w01_bs16_iou03_size448',\n",
      " 'mrcls_bs16_iou03_size448',\n",
      " 'mrcls_dv123_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv23_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_p_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_s_w001_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrpa_bs16_iou03_size448']\n"
     ]
    }
   ],
   "source": [
    "model_path = '../val_output/N4_All/'\n",
    "pprint([each for each in sorted(os.listdir(model_path))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3894dbb1",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../val_output/N4_All/MP_b012_CO_dv0123_bs16_iou03_size896/\n"
     ]
    }
   ],
   "source": [
    "key = 'MP_b012_CO_dv0123_bs16_iou03_size896'\n",
    "if True:\n",
    "    result_path = '../val_output/N4_All/' + key + '/'\n",
    "    print(result_path)\n",
    "    result_list = sorted([each for each in os.listdir(result_path)])\n",
    "\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "    K_pid_score = {}\n",
    "\n",
    "    for k_idx in range(0,5):\n",
    "        K_pid_score[str(k_idx)] = {}\n",
    "\n",
    "        slice_score_list = []\n",
    "        slice_label_list = []\n",
    "\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "        if len(tmp_result_npz) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            tmp_result_npz = tmp_result_npz[0]\n",
    "\n",
    "    #     print(tmp_result_npz)\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "        case_list = tmp_result_file['case']\n",
    "\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if 'cls' in key:\n",
    "            model_slice_score_list = tmp_result_file['cls_pre']\n",
    "\n",
    "        false_positives = np.zeros((0,))\n",
    "        true_positives = np.zeros((0,))\n",
    "        scores = np.zeros((0,))\n",
    "        num_annotations = 0.0\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case = case_list[i]\n",
    "            pid = '_'.join(case.split('_')[:-1])\n",
    "\n",
    "            if pid not in K_pid_score[str(k_idx)]:\n",
    "                K_pid_score[str(k_idx)][pid] = [0]\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            annotations = all_annotations[i]\n",
    "            num_annotations += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            bb_scores = torch.tensor(detections[:,4])\n",
    "            anchorBoxes = torch.tensor(detections[:,:4])\n",
    "            anchors_nms_idx = nms(anchorBoxes, bb_scores, 0.1)\n",
    "            anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "            detections = detections[anchors_nms_idx]\n",
    "\n",
    "            for d in detections:\n",
    "                det_score = d[4]\n",
    "                K_pid_score[str(k_idx)][pid] += [det_score]\n",
    "\n",
    "            try:\n",
    "                slice_score_list.append(np.max(detections[:,4]))\n",
    "            except:\n",
    "                slice_score_list.append(0)\n",
    "            slice_label_list.append(int(annotations.shape[0] != 0))\n",
    "\n",
    "        for pid, score_list in K_pid_score[str(k_idx)].items():\n",
    "            K_pid_score[str(k_idx)][pid] = np.mean(sorted(score_list)[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "04b36d70",
   "metadata": {
    "code_folding": [
     6
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.8154\n",
      "Precision: 0.7345\n",
      "Recall: 0.8023\n",
      "F1-Score: 0.7669\n",
      "0.691773969779336 - 0.050 0.6145\n",
      "0.5122357997414468 - 0.125 0.7661\n",
      "0.3378085749131602 - 0.250 0.8715\n",
      "0.14588923199588893 - 0.500 0.9259\n",
      "0.026256117531664902 - 1.000 0.9572\n",
      "Mean: 0.827\n",
      "AFROC: 0.7671\n",
      "========================================\n",
      "mAP: 0.7746\n",
      "Precision: 0.6645\n",
      "Recall: 0.8010\n",
      "F1-Score: 0.7264\n",
      "0.8596325400043069 - 0.050 0.4777\n",
      "0.7792338336879467 - 0.125 0.6959\n",
      "0.6443295365123495 - 0.250 0.8328\n",
      "0.41234382731968344 - 0.500 0.9156\n",
      "0.14441968744893546 - 1.000 0.9554\n",
      "Mean: 0.7755\n",
      "AFROC: 0.7933\n",
      "========================================\n",
      "mAP: 0.8367\n",
      "Precision: 0.7973\n",
      "Recall: 0.8009\n",
      "F1-Score: 0.7991\n",
      "0.8749577241277748 - 0.050 0.6462\n",
      "0.7670428954002659 - 0.125 0.8147\n",
      "0.5586572803985371 - 0.250 0.8729\n",
      "0.26805680454222625 - 0.500 0.9127\n",
      "0.05040768923748843 - 1.000 0.9342\n",
      "Mean: 0.8361\n",
      "AFROC: 0.856\n",
      "========================================\n",
      "mAP: 0.7810\n",
      "Precision: 0.7043\n",
      "Recall: 0.8007\n",
      "F1-Score: 0.7494\n",
      "0.9125222576362961 - 0.050 0.4679\n",
      "0.8028733250334632 - 0.125 0.7249\n",
      "0.5136689174879147 - 0.250 0.8567\n",
      "0.1543423164586244 - 0.500 0.9176\n",
      "0.006176784141477853 - 1.000 0.9423\n",
      "Mean: 0.7819\n",
      "AFROC: 0.8774\n",
      "========================================\n",
      "mAP: 0.8112\n",
      "Precision: 0.7597\n",
      "Recall: 0.8037\n",
      "F1-Score: 0.7811\n",
      "0.9143389974954156 - 0.050 0.6486\n",
      "0.7740599001743256 - 0.125 0.8093\n",
      "0.49920518141964487 - 0.250 0.8935\n",
      "0.20867427205613667 - 0.500 0.9159\n",
      "0.054887119480698576 - 1.000 0.9364\n",
      "Mean: 0.8407\n",
      "AFROC: 0.8825\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.1\n",
    "CLS_th = 0.01\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "for k_idx in range(0,5):\n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "    \n",
    "    if len(tmp_result_npz) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        tmp_result_npz = tmp_result_npz[0]\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "\n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    pos_pid_list = []\n",
    "    neg_pid_list = []\n",
    "    pos_score_list = []\n",
    "    neg_score_list = []\n",
    "\n",
    "    for i in range(len(case_list)):\n",
    "        case_name = case_list[i]\n",
    "        seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "        \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "  \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        boxes_list = [detections[:,:4] / 448]\n",
    "        scores_list = [detections[:,-1]]\n",
    "        labels_list = np.ones_like(scores_list)\n",
    "    \n",
    "        iou_thr = NMS_IOU\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "        \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        detections = np.array(sorted(detections.tolist(), key=lambda x:x[-1], reverse=True))\n",
    "\n",
    "        for d in detections:\n",
    "            tmp_score = d[4]\n",
    "            \n",
    "            if tmp_score < S_IOU:\n",
    "                continue\n",
    "            \n",
    "            tmp_score = tmp_score * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "            scores = np.append(scores, tmp_score)\n",
    "            \n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                \n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU:\n",
    "                if assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                    \n",
    "                    if seg_anno_name[0] != 'I':\n",
    "                        pos_pid_list.append(seg_anno_name)\n",
    "                        pos_score_list.append(tmp_score)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "            else:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "    \n",
    "    anno_list[k_idx] = num_annotations\n",
    "    if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "        print('No detection')\n",
    "    else:\n",
    "        # sort by score\n",
    "        indices = np.argsort(-scores)\n",
    "        scores = scores[indices]\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "        \n",
    "        anno = num_annotations\n",
    "        case_num = len(case_list)\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "        \n",
    "        # compute average precision\n",
    "        average_precision = compute_ap(recall, precision)\n",
    "        \n",
    "        recall_copy = deepcopy(recall)\n",
    "        recall_copy[recall_copy < 0.8] = 0\n",
    "        recall_th_idx = np.argmin(np.abs(recall_copy - 0.8))\n",
    "        \n",
    "        recall_max = recall[recall_th_idx]\n",
    "        precision_max = precision[recall_th_idx]\n",
    "        while precision[recall_th_idx] >= precision_max:\n",
    "            recall_th_idx += 1\n",
    "            \n",
    "        recall = recall[recall_th_idx]\n",
    "        precision = precision[recall_th_idx]\n",
    "\n",
    "        print('mAP: {:.4f}'.format(average_precision))\n",
    "        print(\"Precision: {:.4f}\".format(precision))\n",
    "        print(\"Recall: {:.4f}\".format(recall))\n",
    "        print(\"F1-Score: {:.4f}\".format(2*recall*precision/(recall+precision)))\n",
    "\n",
    "        fp_list = false_positives\n",
    "        tp_list = true_positives\n",
    "        \n",
    "        fps_list = []\n",
    "        \n",
    "        for th in [0.05, 0.125, 0.25, 0.5, 1]:\n",
    "            fp_th_idx = np.argmin(np.abs(fp_list / case_num - th))\n",
    "            tp_th = tp_list[fp_th_idx]\n",
    "            print('%s - %1.3f'%(scores[fp_th_idx], th), (tp_th / anno).round(4))\n",
    "            fps_list.append(tp_th / anno)\n",
    "        print('Mean:', np.mean(fps_list).round(4))\n",
    "    \n",
    "    unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "    unique_score_list.insert(0, -1)\n",
    "    unique_score_list.append(1.1)\n",
    "    \n",
    "    unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "    Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "\n",
    "    sens_case_list = []\n",
    "    spec_pid_list = []\n",
    "\n",
    "    for th_score in unique_score_list:\n",
    "        TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "        sens_case = TP_case_num / num_annotations\n",
    "        sens_case_list.append(sens_case)\n",
    "        \n",
    "        FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "        spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "#     for sens_idx, sens in enumerate(sens_case_list):\n",
    "#         print(sens, spec_pid_list[sens_idx])\n",
    "    \n",
    "    \n",
    "#     fig = plt.figure(figsize=(10,10),dpi=100)\n",
    "#     plt.plot(spec_pid_list, sens_case_list)\n",
    "#     plt.xlim(-0.1,1.1)\n",
    "#     plt.ylim(-0.1,1.1)\n",
    "#     plt.show()\n",
    "#     break\n",
    "    \n",
    "    print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "    print('========================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "02060d44",
   "metadata": {
    "code_folding": [
     16,
     18,
     33,
     120
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.7793\n",
      "Precision: 0.6984\n",
      "Recall: 0.8000\n",
      "F1-Score: 0.7457\n",
      "0.8723435002650959 - 0.050 0.5116\n",
      "0.7494993621327122 - 0.125 0.7327\n",
      "0.5166639257073864 - 0.250 0.8551\n",
      "0.2412618833966723 - 0.500 0.9149\n",
      "0.058683584976737535 - 1.000 0.9452\n",
      "Mean: 0.7919\n",
      "AFROC: 0.8341\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.1\n",
    "CLS_th = 0.01\n",
    "\n",
    "false_positives = np.zeros((0,))\n",
    "true_positives = np.zeros((0,))\n",
    "scores = np.zeros((0,))\n",
    "num_annotations = 0.0\n",
    "case_num = 0\n",
    "\n",
    "pos_pid_list = []\n",
    "neg_pid_list = []\n",
    "pos_score_list = []\n",
    "neg_score_list = []\n",
    "\n",
    "if True:\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "\n",
    "        if len(tmp_result_npz) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            tmp_result_npz = tmp_result_npz[0]\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "        case_list = tmp_result_file['case']\n",
    "        case_num += len(case_list)\n",
    "\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case_name = case_list[i]\n",
    "            seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            annotations = all_annotations[i]\n",
    "            num_annotations += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            if len(detections) == 0:\n",
    "                if annotations.shape[0] == 0:\n",
    "                    if seg_anno_name[0] == 'I':\n",
    "                        neg_pid_list.append(seg_anno_name)\n",
    "                        neg_score_list.append(0)\n",
    "                continue\n",
    "\n",
    "            boxes_list = [detections[:,:4] / 448]\n",
    "            scores_list = [detections[:,-1]]\n",
    "            labels_list = np.ones_like(scores_list)\n",
    "\n",
    "            iou_thr = NMS_IOU\n",
    "            skip_box_thr = 0.0001\n",
    "\n",
    "            boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                                scores_list, \n",
    "                                                labels_list, \n",
    "                                                iou_thr=iou_thr,\n",
    "                                                skip_box_thr=skip_box_thr)\n",
    "\n",
    "            boxes = boxes * 448\n",
    "            nms_scores = nms_scores[:,np.newaxis]\n",
    "            detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "\n",
    "            if len(detections) == 0:\n",
    "                if annotations.shape[0] == 0:\n",
    "                    if seg_anno_name[0] == 'I':\n",
    "                        neg_pid_list.append(seg_anno_name)\n",
    "                        neg_score_list.append(0)\n",
    "                continue\n",
    "\n",
    "            detections = np.array(sorted(detections.tolist(), key=lambda x:x[-1], reverse=True))\n",
    "\n",
    "            for d in detections:\n",
    "                tmp_score = d[4]\n",
    "\n",
    "                if tmp_score < S_IOU:\n",
    "                    continue\n",
    "\n",
    "                tmp_score = tmp_score * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "                scores = np.append(scores, tmp_score)\n",
    "\n",
    "                if annotations.shape[0] == 0:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "\n",
    "                    if seg_anno_name[0] == 'I':\n",
    "                        neg_pid_list.append(seg_anno_name)\n",
    "                        neg_score_list.append(tmp_score)\n",
    "                    continue\n",
    "\n",
    "                d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "                a_tensor = torch.tensor(annotations)\n",
    "                overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "                if max_overlap >= H_IOU:\n",
    "                    if assigned_annotation not in detected_annotations:\n",
    "                        false_positives = np.append(false_positives, 0)\n",
    "                        true_positives = np.append(true_positives, 1)\n",
    "                        detected_annotations.append(assigned_annotation)\n",
    "\n",
    "                        if seg_anno_name[0] != 'I':\n",
    "                            pos_pid_list.append(seg_anno_name)\n",
    "                            pos_score_list.append(tmp_score)\n",
    "                    else:\n",
    "                        false_positives = np.append(false_positives, 1)\n",
    "                        true_positives = np.append(true_positives, 0)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "                    if seg_anno_name[0] == 'I':\n",
    "                        neg_pid_list.append(seg_anno_name)\n",
    "                        neg_score_list.append(tmp_score)\n",
    "\n",
    "    if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "        print('No detection')\n",
    "    else:\n",
    "        # sort by score\n",
    "        indices = np.argsort(-scores)\n",
    "        scores = scores[indices]\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "\n",
    "        anno = num_annotations\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision = compute_ap(recall, precision)\n",
    "\n",
    "        recall_copy = deepcopy(recall)\n",
    "        recall_copy[recall_copy < 0.8] = 0\n",
    "        recall_th_idx = np.argmin(np.abs(recall_copy - 0.8))\n",
    "\n",
    "        recall_max = recall[recall_th_idx]\n",
    "        precision_max = precision[recall_th_idx]\n",
    "        while precision[recall_th_idx] >= precision_max:\n",
    "            recall_th_idx += 1\n",
    "\n",
    "        recall = recall[recall_th_idx]\n",
    "        precision = precision[recall_th_idx]\n",
    "\n",
    "        print('mAP: {:.4f}'.format(average_precision))\n",
    "        print(\"Precision: {:.4f}\".format(precision))\n",
    "        print(\"Recall: {:.4f}\".format(recall))\n",
    "        print(\"F1-Score: {:.4f}\".format(2*recall*precision/(recall+precision)))\n",
    "\n",
    "        fp_list = false_positives\n",
    "        tp_list = true_positives\n",
    "\n",
    "        fps_list = []\n",
    "\n",
    "        for th in [0.05, 0.125, 0.25, 0.5, 1]:\n",
    "            fp_th_idx = np.argmin(np.abs(fp_list / case_num - th))\n",
    "            tp_th = tp_list[fp_th_idx]\n",
    "            print('%s - %1.3f'%(scores[fp_th_idx], th), (tp_th / anno).round(4))\n",
    "            fps_list.append(tp_th / anno)\n",
    "        print('Mean:', np.mean(fps_list).round(4))\n",
    "\n",
    "    unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "    unique_score_list.insert(0, -1)\n",
    "    unique_score_list.append(1.1)\n",
    "\n",
    "    unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "    Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "\n",
    "    sens_case_list = []\n",
    "    spec_pid_list = []\n",
    "\n",
    "    for th_score in unique_score_list:\n",
    "        TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "        sens_case = TP_case_num / num_annotations\n",
    "        sens_case_list.append(sens_case)\n",
    "\n",
    "        FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "        spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "#     fig = plt.figure(figsize=(10,10),dpi=100)\n",
    "#     plt.plot(spec_pid_list, sens_case_list)\n",
    "#     plt.xlim(-0.1,1.1)\n",
    "#     plt.ylim(-0.1,1.1)\n",
    "#     plt.show()\n",
    "\n",
    "    print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "    print('========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "001c6ae2",
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9551\n",
      "0.9492\n",
      "0.9592\n",
      "0.9\n",
      "======================================\n",
      "0.9755\n",
      "0.8983\n",
      "0.9592\n",
      "0.6\n",
      "======================================\n",
      "0.9612\n",
      "0.8644\n",
      "0.898\n",
      "0.7\n",
      "======================================\n",
      "0.9773\n",
      "0.7586\n",
      "0.7143\n",
      "1.0\n",
      "======================================\n",
      "0.9583\n",
      "0.8421\n",
      "0.8333\n",
      "0.8889\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.01\n",
    "top = 3\n",
    "th = 0.7\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "for k_idx in range(0,5):\n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "    if len(tmp_result_npz) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        tmp_result_npz = tmp_result_npz[0]\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "\n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    pid_dict = {}\n",
    "\n",
    "    for i in range(len(case_list)):\n",
    "        case = case_list[i]\n",
    "        pid = '_'.join(case.split('_')[:-1])\n",
    "        \n",
    "        if pid not in pid_dict:\n",
    "            pid_dict[pid] = [0]\n",
    "        \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "        \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "#         bb_scores = torch.tensor(detections[:,4])\n",
    "#         anchorBoxes = torch.tensor(detections[:,:4])\n",
    "#         anchors_nms_idx = nms(anchorBoxes, bb_scores, NMS_IOU)\n",
    "#         anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "#         detections = detections[anchors_nms_idx]\n",
    "        \n",
    "        boxes_list = [detections[:,:4] / 448]\n",
    "        scores_list = [detections[:,-1]]\n",
    "        labels_list = np.ones_like(scores_list)\n",
    "    \n",
    "        iou_thr = NMS_IOU\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "        \n",
    "        for d in detections:\n",
    "            det_score = d[4] * K_pid_score[str(k_idx)][pid]\n",
    "            pid_dict[pid] += [det_score]\n",
    "\n",
    "    score_list = []\n",
    "    label_list = []\n",
    "    for pid in pid_dict:\n",
    "        if pid[:2] == 'I_':\n",
    "            label_list.append(0)\n",
    "        else:\n",
    "            label_list.append(1)\n",
    "        score_list.append(np.mean(sorted(pid_dict[pid], reverse=True)[:top]))\n",
    "        \n",
    "    score_list = np.array(score_list)\n",
    "    label_list = np.array(label_list)\n",
    "    \n",
    "    print(round(roc_auc_score(label_list, score_list),4))\n",
    "    print(round(accuracy_score(label_list, score_list>th),4))\n",
    "    print(round(recall_score(label_list, score_list>th),4))\n",
    "    print(round(recall_score(1-label_list, score_list<=th),4))\n",
    "    print('======================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c36d62",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for H_IOU in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    print('=========== Hit IoU %s ========='%H_IOU)\n",
    "    S_IOU = 0.05\n",
    "    NMS_IOU = 0.01\n",
    "\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "        if len(tmp_result_npz) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            tmp_result_npz = tmp_result_npz[0]\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "        case_list = tmp_result_file['case']\n",
    "\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        false_positives = np.zeros((0,))\n",
    "        true_positives = np.zeros((0,))\n",
    "        scores = np.zeros((0,))\n",
    "        num_annotations = 0.0\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case = case_list[i]\n",
    "            pid = '_'.join(case.split('_')[:-1])\n",
    "            \n",
    "            detections = all_detections[i]\n",
    "            annotations = all_annotations[i]\n",
    "            num_annotations += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            boxes_list = [detections[:,:4] / 448]\n",
    "            scores_list = [detections[:,-1]]\n",
    "            labels_list = np.ones_like(scores_list)\n",
    "\n",
    "            iou_thr = NMS_IOU\n",
    "            skip_box_thr = 0.0001\n",
    "\n",
    "            boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                                scores_list, \n",
    "                                                labels_list, \n",
    "                                                iou_thr=iou_thr,\n",
    "                                                skip_box_thr=skip_box_thr)\n",
    "\n",
    "            boxes = boxes * 448\n",
    "            nms_scores = nms_scores[:,np.newaxis]\n",
    "            detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "\n",
    "            for d in detections:\n",
    "                if d[4] < S_IOU:\n",
    "                    continue\n",
    "                \n",
    "                tmp_score = d[4]  * K_pid_score[str(k_idx)][pid]\n",
    "                scores = np.append(scores, tmp_score)\n",
    "\n",
    "                if annotations.shape[0] == 0:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "                    continue\n",
    "\n",
    "                d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "                a_tensor = torch.tensor(annotations)\n",
    "                overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "                if max_overlap >= H_IOU and assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "\n",
    "        if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "            print('No detection')\n",
    "        else:\n",
    "            # sort by score\n",
    "            indices = np.argsort(-scores)\n",
    "            scores = scores[indices]\n",
    "            false_positives = false_positives[indices]\n",
    "            true_positives = true_positives[indices]\n",
    "\n",
    "            anno = num_annotations\n",
    "            case_num = len(case_list)\n",
    "\n",
    "            # compute false positives and true positives\n",
    "            false_positives = np.cumsum(false_positives)\n",
    "            true_positives = np.cumsum(true_positives)\n",
    "\n",
    "            # compute recall and precision\n",
    "            recall = true_positives / num_annotations\n",
    "            precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "            # compute average precision\n",
    "            average_precision = compute_ap(recall, precision)\n",
    "\n",
    "            print('mAP: {:.4f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d86c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aead641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e4ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
