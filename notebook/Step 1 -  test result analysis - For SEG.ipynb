{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663dd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, auc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision.ops import box_iou, nms\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688cfbd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_list = [ 592]\n",
    "case_list = [2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb77ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_anno_path = '../data/N4_SEG_img/'\n",
    "SEG_anno_list = sorted(os.listdir(SEG_anno_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563022f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_count_dict = {}\n",
    "\n",
    "for seg_anno in tqdm(SEG_anno_list):\n",
    "    seg_anno_name = '_'.join(seg_anno.split('_')[:-1])\n",
    "    if seg_anno_name not in seg_count_dict:\n",
    "        seg_count_dict[seg_anno_name] = {'GT':[],\n",
    "                                         'Hit':[]}\n",
    "    seg_anno_array = np.load(SEG_anno_path + seg_anno)['BBOX']\n",
    "    seg_anno_label_list = np.unique(seg_anno_array).tolist()\n",
    "    for anno_label in seg_anno_label_list:\n",
    "        if anno_label == 0:\n",
    "            continue\n",
    "        elif anno_label in seg_count_dict[seg_anno_name]['GT']:\n",
    "            continue\n",
    "        else:\n",
    "            seg_count_dict[seg_anno_name]['GT'].append(anno_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_label_list = []\n",
    "for name in seg_count_dict:\n",
    "    seg_label_list += seg_count_dict[name]['GT']\n",
    "    \n",
    "len(seg_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a445a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seg_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(seg_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58425538",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../test_output/N4_All/'\n",
    "pprint([each for each in sorted(os.listdir(model_path))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'mask_rcnn_FLAIR_SEG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93705548",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = '../test_output/N4_All/' + key + '/'\n",
    "print(result_path)\n",
    "result_list = sorted([each for each in os.listdir(result_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a3b4e",
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "NMS_IOU = 0.01\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "K_pid_score = {}\n",
    "\n",
    "for k_idx in range(0,5):\n",
    "    K_pid_score[str(k_idx)] = {}\n",
    "    \n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "    print(tmp_result_npz)\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "\n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    for i in range(len(case_list)):\n",
    "        case = case_list[i]\n",
    "        pid = '_'.join(case.split('_')[:-1])\n",
    "        \n",
    "        if pid not in K_pid_score[str(k_idx)]:\n",
    "            K_pid_score[str(k_idx)][pid] = []\n",
    "        \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "        \n",
    "        bb_scores = torch.tensor(detections[:,4])\n",
    "        anchorBoxes = torch.tensor(detections[:,:4])\n",
    "        anchors_nms_idx = nms(anchorBoxes, bb_scores, 0.1)\n",
    "        anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "        detections = detections[anchors_nms_idx]\n",
    "        \n",
    "        for d in detections:\n",
    "            det_score = d[4]\n",
    "            K_pid_score[str(k_idx)][pid] += [det_score]\n",
    "    \n",
    "    for pid, score_list in K_pid_score[str(k_idx)].items():\n",
    "        K_pid_score[str(k_idx)][pid] = np.mean(sorted(score_list)[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b36d70",
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.01\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "for k_idx in range(0,5):\n",
    "    Count_dict = deepcopy(seg_count_dict)\n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "    print(tmp_result_npz)\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "\n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    pid_seg_tp_score = {}\n",
    "    neg_seg_fp_score = {}\n",
    "    neg_pid_list = []\n",
    "    neg_score_list = []\n",
    "    \n",
    "    for i in range(len(case_list)):\n",
    "        case_name = case_list[i]\n",
    "        seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "        \n",
    "        if seg_anno_name not in pid_seg_tp_score:\n",
    "            pid_seg_tp_score[seg_anno_name] = {}\n",
    "            \n",
    "        if seg_anno_name not in neg_seg_fp_score and seg_anno_name[0] == 'I':\n",
    "            neg_seg_fp_score[seg_anno_name] = 0\n",
    "        \n",
    "        if case_name + '.npz' in SEG_anno_list:\n",
    "            SEG_anno = np.load(SEG_anno_path + case_name + '.npz')['BBOX']\n",
    "                \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        \n",
    "        bb_scores = torch.tensor(detections[:,4])\n",
    "        anchorBoxes = torch.tensor(detections[:,:4])\n",
    "        anchors_nms_idx = nms(anchorBoxes, bb_scores, NMS_IOU)\n",
    "        anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "        detections = detections[anchors_nms_idx]\n",
    "        \n",
    "        if len(detections) == 0 and annotations.shape[0] == 0 and seg_anno_name[0] == 'I':\n",
    "            neg_pid_list.append(seg_anno_name)\n",
    "            neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        for d in detections:\n",
    "            if d[4] < S_IOU:\n",
    "                continue\n",
    "                \n",
    "            tmp_score = d[4]  * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "            \n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                \n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                    neg_seg_fp_score[seg_anno_name] = max(neg_seg_fp_score[seg_anno_name], tmp_score)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU:\n",
    "                x1,y1,x2,y2 = a_tensor[assigned_annotation].data.numpy().astype('uint16')[0]\n",
    "                x_mid = (x1+x2)//2\n",
    "                y_mid = (y1+y2)//2\n",
    "\n",
    "                hit_anno = SEG_anno[y_mid, x_mid]\n",
    "                if hit_anno == 0:\n",
    "                    continue\n",
    "                elif hit_anno in Count_dict[seg_anno_name]['Hit']:\n",
    "                    continue\n",
    "                else:\n",
    "                    Count_dict[seg_anno_name]['Hit'].append(hit_anno)\n",
    "                    \n",
    "                if seg_anno_name[0] != 'I':\n",
    "                    hit_anno_name = str(hit_anno)\n",
    "                    if hit_anno_name not in pid_seg_tp_score[seg_anno_name]:\n",
    "                        pid_seg_tp_score[seg_anno_name][hit_anno_name] = tmp_score\n",
    "                    else:\n",
    "                        ori_score = pid_seg_tp_score[seg_anno_name][hit_anno_name]\n",
    "                        pid_seg_tp_score[seg_anno_name][hit_anno_name] = max(ori_score, tmp_score)\n",
    "            else:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                    neg_seg_fp_score[seg_anno_name] = max(neg_seg_fp_score[seg_anno_name], tmp_score)\n",
    "    \n",
    "    seg_label_list = []\n",
    "    hit_label_list = []\n",
    "    for name in Count_dict:\n",
    "        seg_label_list += Count_dict[name]['GT']\n",
    "        hit_label_list += Count_dict[name]['Hit']\n",
    "    \n",
    "    seg_num = len(seg_label_list)\n",
    "    hit_num = len(hit_label_list)\n",
    "    \n",
    "    pos_score_list = []\n",
    "    for pid in pid_seg_tp_score:\n",
    "        for hit_anno_name in pid_seg_tp_score[pid]:\n",
    "            score = pid_seg_tp_score[pid][hit_anno_name]\n",
    "            pos_score_list.append(score)\n",
    "            \n",
    "    unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "    unique_score_list.insert(0, -1)\n",
    "    unique_score_list.append(1.1)\n",
    "    \n",
    "    unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "    Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "    \n",
    "    sens_case_list = []\n",
    "    spec_pid_list = []\n",
    "\n",
    "    for th_score in unique_score_list:\n",
    "        TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "        sens_case = TP_case_num / seg_num\n",
    "        sens_case_list.append(sens_case)\n",
    "        \n",
    "        FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "        spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "#     for sens_idx, sens in enumerate(sens_case_list):\n",
    "#         print(sens, spec_pid_list[sens_idx])\n",
    "    \n",
    "\n",
    "#     fig = plt.figure(figsize=(6,6),dpi=100)\n",
    "#     plt.plot(spec_pid_list, sens_case_list)\n",
    "#     plt.xlim(-0.1,1.1)\n",
    "#     plt.ylim(-0.1,1.1)\n",
    "#     plt.show()\n",
    "#     break\n",
    "\n",
    "    print(seg_num, hit_num, round(hit_num / seg_num,4))\n",
    "    print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "    \n",
    "    for i in sorted(list(set(seg_label_list))):\n",
    "        hit_num = np.sum(np.array(hit_label_list)==i)\n",
    "        seg_num = np.sum(np.array(seg_label_list)==i)\n",
    "        print(i, hit_num, seg_num, (hit_num / seg_num).round(4))\n",
    "        \n",
    "    print('==================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d86c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
