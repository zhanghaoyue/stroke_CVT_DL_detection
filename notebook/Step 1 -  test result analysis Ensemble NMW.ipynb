{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "663dd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, auc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision.ops import box_iou, nms\n",
    "from tqdm import tqdm\n",
    "from ensemble_boxes import nms as wbf_nms\n",
    "from ensemble_boxes import soft_nms as wbf_snms\n",
    "from ensemble_boxes import non_maximum_weighted, weighted_boxes_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d688cfbd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8820ba7",
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 612/612 [00:01<00:00, 322.61it/s]\n"
     ]
    }
   ],
   "source": [
    "SEG_anno_path = '../data/N4_SEG_img/'\n",
    "SEG_anno_list = sorted(os.listdir(SEG_anno_path))\n",
    "\n",
    "seg_count_dict = {}\n",
    "\n",
    "for seg_anno in tqdm(SEG_anno_list):\n",
    "    seg_anno_name = '_'.join(seg_anno.split('_')[:-1])\n",
    "    if seg_anno_name not in seg_count_dict:\n",
    "        seg_count_dict[seg_anno_name] = {'GT':[],\n",
    "                                         'Hit':[]}\n",
    "    seg_anno_array = np.load(SEG_anno_path + seg_anno)['BBOX']\n",
    "    seg_anno_label_list = np.unique(seg_anno_array).tolist()\n",
    "    for anno_label in seg_anno_label_list:\n",
    "        if anno_label == 0:\n",
    "            continue\n",
    "        elif anno_label in seg_count_dict[seg_anno_name]['GT']:\n",
    "            continue\n",
    "        else:\n",
    "            seg_count_dict[seg_anno_name]['GT'].append(anno_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58425538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MCS_NL23_bs16_iou03_size448',\n",
      " 'MCS_NL3_bs16_iou03_size448',\n",
      " 'MCSdv0123_bs16_iou03_size448',\n",
      " 'MCSdv123_bs16_iou03_size448',\n",
      " 'MCSdv23_bs16_iou03_size448',\n",
      " 'MCSdv23_bs16_iou03_size896',\n",
      " 'MCSdv3_bs16_iou03_size448',\n",
      " 'MC_CO_dv0123_bs16_iou03_size448',\n",
      " 'MC_CO_dv123_bs16_iou03_size448',\n",
      " 'MC_CO_dv23_bs16_iou03_size448',\n",
      " 'MC_CO_dv23_bs16_iou03_size896',\n",
      " 'MC_CO_dv3_bs16_iou03_size448',\n",
      " 'MC_CO_dv3_bs16_iou03_size896',\n",
      " 'MC_SE_dv3_bs16_iou03_size896',\n",
      " 'MCpre_bs16_iou03_size672',\n",
      " 'MCpre_bs16_iou03_size896',\n",
      " 'mask_rcnn_1_SEG',\n",
      " 'mask_rcnn_FLAIR_SEG',\n",
      " 'mask_rcnn_T1T2',\n",
      " 'mask_rcnn_T1_SEG',\n",
      " 'mask_rcnn_T2FLAIR',\n",
      " 'mask_rcnn_T2_SEG',\n",
      " 'mrDS_bs16_iou03_size892',\n",
      " 'mrSAdv23_bs16_iou03_size448',\n",
      " 'mrSAdv23_bs16_iou03_size896',\n",
      " 'mrSAdv3_bs16_iou03_size448',\n",
      " 'mrSAdv3_bs16_iou03_size896',\n",
      " 'mr_bs16_iou03_size448_base1',\n",
      " 'mr_bs16_iou03_size448_base2',\n",
      " 'mr_bs16_iou03_size896',\n",
      " 'mr_bs16_iou03_size896_base2',\n",
      " 'mrcls',\n",
      " 'mrcls3w01_bs16_iou03_size448',\n",
      " 'mrcls_BCE_p_w01_bs16_iou03_size448',\n",
      " 'mrcls_BCE_s_w01_bs16_iou03_size448',\n",
      " 'mrcls_CE_p_w01_bs16_iou03_size448',\n",
      " 'mrcls_CE_s_w01_bs16_iou03_size448',\n",
      " 'mrcls_bs16_iou03_size448',\n",
      " 'mrcls_dv123_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv23_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_p_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_s_w001_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrpa_bs16_iou03_size448']\n"
     ]
    }
   ],
   "source": [
    "model_path = '../test_output/N4_All/'\n",
    "pprint([each for each in sorted(os.listdir(model_path))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3894dbb1",
   "metadata": {
    "code_folding": [
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../test_output/N4_All/MP_b012_CO_dv0123_bs16_iou03_size896/\n",
      "K0_output.npz\n",
      "K1_output.npz\n",
      "K2_output.npz\n",
      "K3_output.npz\n",
      "K4_output.npz\n"
     ]
    }
   ],
   "source": [
    "key = 'MP_b012_CO_dv0123_bs16_iou03_size896'\n",
    "\n",
    "result_path = '../test_output/N4_All/' + key + '/'\n",
    "print(result_path)\n",
    "result_list = sorted([each for each in os.listdir(result_path)])\n",
    "\n",
    "NMS_IOU = 0.01\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "K_pid_score = {}\n",
    "\n",
    "for k_idx in range(0,5):\n",
    "    K_pid_score[str(k_idx)] = {}\n",
    "    \n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "    print(tmp_result_npz)\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "\n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    for i in range(len(case_list)):\n",
    "        case = case_list[i]\n",
    "        pid = '_'.join(case.split('_')[:-1])\n",
    "        \n",
    "        if pid not in K_pid_score[str(k_idx)]:\n",
    "            K_pid_score[str(k_idx)][pid] = [0]\n",
    "        \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "        \n",
    "        bb_scores = torch.tensor(detections[:,4])\n",
    "        anchorBoxes = torch.tensor(detections[:,:4])\n",
    "        anchors_nms_idx = nms(anchorBoxes, bb_scores, 0.1)\n",
    "        anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "        detections = detections[anchors_nms_idx]\n",
    "        \n",
    "        for d in detections:\n",
    "            det_score = d[4]\n",
    "            K_pid_score[str(k_idx)][pid] += [det_score]\n",
    "    \n",
    "    for pid, score_list in K_pid_score[str(k_idx)].items():\n",
    "        K_pid_score[str(k_idx)][pid] = np.mean(sorted(score_list)[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "04b36d70",
   "metadata": {
    "code_folding": [
     4,
     92
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K0_output.npz\n",
      "K1_output.npz\n",
      "K2_output.npz\n",
      "K3_output.npz\n",
      "K4_output.npz\n",
      "mAP: 0.8402\n",
      "Precision: 0.7178\n",
      "Recall: 0.8003\n",
      "F1-Score: 0.7568\n",
      "0.8747839331626892 - 0.050 0.7201\n",
      "0.7711428999900818 - 0.125 0.8245\n",
      "0.6408675312995911 - 0.250 0.8865\n",
      "0.42179757356643677 - 0.500 0.9365\n",
      "0.20117351412773132 - 1.000 0.9531\n",
      "Mean: 0.8641\n",
      "AFROC: 0.8234\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.1\n",
    "# nms, snms, nmw, wbf\n",
    "if True:\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "\n",
    "    ensemble_case_list = None\n",
    "    ensemble_detections = []\n",
    "    ensemble_annotations = None\n",
    "\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "        print(tmp_result_npz)\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "\n",
    "        case_list = tmp_result_file['case']\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if k_idx == 0:\n",
    "            ensemble_case_list = case_list\n",
    "            ensemble_annotations = all_annotations\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case_name = case_list[i]\n",
    "            seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            detections[:,4] = detections[:,4] * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if k_idx == 0:\n",
    "                ensemble_detections.append([detections])\n",
    "            else:\n",
    "                ensemble_detections[i] += [detections]\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    pos_pid_list = []\n",
    "    neg_pid_list = []\n",
    "    pos_score_list = []\n",
    "    neg_score_list = []\n",
    "\n",
    "    for i in range(len(ensemble_case_list)):\n",
    "        case_name = ensemble_case_list[i]\n",
    "        seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "        \n",
    "        annotations = ensemble_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "        \n",
    "        detections = ensemble_detections[i]\n",
    "        detections_concat = np.concatenate(detections, axis=0)\n",
    "        \n",
    "        if len(detections_concat) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        boxes_list = [each[:,:4] / 448 for each in detections]\n",
    "        scores_list = [each[:,-1] for each in detections]\n",
    "        labels_list = [np.ones_like(each[:,-1]) for each in detections]\n",
    "        weights = [1,1,1,1,1]\n",
    "        iou_thr = NMS_IOU\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            weights=weights, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "        \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "\n",
    "        detections = np.array(sorted(detections.tolist(), key=lambda x:x[-1], reverse=True))\n",
    "\n",
    "        for d in detections:\n",
    "            if d[4] < S_IOU:\n",
    "                continue\n",
    "\n",
    "            tmp_score = d[4]# * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "            scores = np.append(scores, tmp_score)\n",
    "\n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU:\n",
    "                if assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "\n",
    "                    if seg_anno_name[0] != 'I':\n",
    "                        pos_pid_list.append(seg_anno_name)\n",
    "                        pos_score_list.append(tmp_score)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "            else:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "\n",
    "    if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "        print('No detection')\n",
    "    else:\n",
    "        # sort by score\n",
    "        indices = np.argsort(-scores)\n",
    "        scores = scores[indices]\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "\n",
    "        anno = num_annotations\n",
    "        case_num = len(case_list)\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision = compute_ap(recall, precision)\n",
    "\n",
    "        recall_copy = deepcopy(recall)\n",
    "        recall_copy[recall_copy < 0.8] = 0\n",
    "        recall_th_idx = np.argmin(np.abs(recall_copy - 0.8))\n",
    "\n",
    "        recall_max = recall[recall_th_idx]\n",
    "        precision_max = precision[recall_th_idx]\n",
    "        while precision[recall_th_idx] >= precision_max:\n",
    "            recall_th_idx += 1\n",
    "\n",
    "        recall = recall[recall_th_idx]\n",
    "        precision = precision[recall_th_idx]\n",
    "\n",
    "        print('mAP: {:.4f}'.format(average_precision))\n",
    "        print(\"Precision: {:.4f}\".format(precision))\n",
    "        print(\"Recall: {:.4f}\".format(recall))\n",
    "        print(\"F1-Score: {:.4f}\".format(2*recall*precision/(recall+precision)))\n",
    "\n",
    "        fp_list = false_positives\n",
    "        tp_list = true_positives\n",
    "\n",
    "        fps_list = []\n",
    "\n",
    "        for th in [0.05, 0.125, 0.25, 0.5, 1]:\n",
    "            fp_th_idx = np.argmin(np.abs(fp_list / case_num - th))\n",
    "            tp_th = tp_list[fp_th_idx]\n",
    "            print('%s - %1.3f'%(scores[fp_th_idx], th), (tp_th / anno).round(4))\n",
    "            fps_list.append(tp_th / anno)\n",
    "        print('Mean:', np.mean(fps_list).round(4))\n",
    "\n",
    "    unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "    unique_score_list.insert(0, -1)\n",
    "    unique_score_list.append(1.1)\n",
    "\n",
    "    unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "    Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "\n",
    "    sens_case_list = []\n",
    "    spec_pid_list = []\n",
    "\n",
    "    for th_score in unique_score_list:\n",
    "        TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "        sens_case = TP_case_num / num_annotations\n",
    "        sens_case_list.append(sens_case)\n",
    "\n",
    "        FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "        spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "    print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "    print('========================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b282b5ac",
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K0_output.npz\n",
      "K1_output.npz\n",
      "K2_output.npz\n",
      "K3_output.npz\n",
      "K4_output.npz\n",
      "AUC: 0.942\n",
      "ACC: 0.86\n",
      "Sens: 0.94\n",
      "Spec: 0.78\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.1\n",
    "th = 0.8\n",
    "\n",
    "if True:\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "\n",
    "    ensemble_case_list = None\n",
    "    ensemble_detections = []\n",
    "    ensemble_annotations = None\n",
    "\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "        print(tmp_result_npz)\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "\n",
    "        case_list = tmp_result_file['case']\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if k_idx == 0:\n",
    "            ensemble_case_list = case_list\n",
    "            ensemble_annotations = all_annotations\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case_name = case_list[i]\n",
    "            seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            detections[:,4] = detections[:,4] * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if k_idx == 0:\n",
    "                ensemble_detections.append([detections])\n",
    "            else:\n",
    "                ensemble_detections[i] += [detections]\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    pid_dict = {}\n",
    "\n",
    "    for i in range(len(ensemble_case_list)):\n",
    "        case = ensemble_case_list[i]\n",
    "        pid = '_'.join(case.split('_')[:-1])\n",
    "\n",
    "        if pid not in pid_dict:\n",
    "            pid_dict[pid] = 0\n",
    "            \n",
    "        annotations = ensemble_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "\n",
    "        detections = ensemble_detections[i]\n",
    "        detections_concat = np.concatenate(detections, axis=0)\n",
    "        \n",
    "        if len(detections_concat) == 0:\n",
    "            continue\n",
    "        \n",
    "        boxes_list = [each[:,:4] / 448 for each in detections]\n",
    "        scores_list = [each[:,-1] for each in detections]\n",
    "        labels_list = [np.ones_like(each[:,-1]) for each in detections]\n",
    "        weights = [1,1,1,1,1]\n",
    "        iou_thr = 0.1\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            weights=weights, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "\n",
    "        for d in detections:\n",
    "            det_score = d[4]\n",
    "            pid_dict[pid] = max(pid_dict[pid], det_score)\n",
    "\n",
    "    score_list = []\n",
    "    label_list = []\n",
    "    for pid in pid_dict:\n",
    "        if pid[:2] == 'I_':\n",
    "            label_list.append(0)\n",
    "        else:\n",
    "            label_list.append(1)\n",
    "        score_list.append(pid_dict[pid])\n",
    "\n",
    "    score_list = np.array(score_list)\n",
    "    label_list = np.array(label_list)\n",
    "\n",
    "    print('AUC:',round(roc_auc_score(label_list, score_list),4))\n",
    "    print('ACC:',round(accuracy_score(label_list, score_list>th),4))\n",
    "    print('Sens:',round(recall_score(label_list, score_list>th),4))\n",
    "    print('Spec:',round(recall_score(1-label_list, score_list<=th),4))\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "76d86c7b",
   "metadata": {
    "code_folding": [
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 144 0.9863\n",
      "AFROC: 0.8547\n",
      " 1  8  8 1.0\n",
      " 3 17 17 1.0\n",
      " 4 19 19 1.0\n",
      " 5 28 28 1.0\n",
      " 6 29 30 0.9667\n",
      " 7  4  5 0.8\n",
      " 8  6  6 1.0\n",
      " 9 33 33 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.01\n",
    "    \n",
    "Count_dict = deepcopy(seg_count_dict)\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "\n",
    "ensemble_case_list = None\n",
    "ensemble_detections = []\n",
    "ensemble_annotations = None\n",
    "\n",
    "if True:\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "\n",
    "        case_list = tmp_result_file['case']\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if k_idx == 0:\n",
    "            ensemble_case_list = case_list\n",
    "            ensemble_annotations = all_annotations\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case_name = case_list[i]\n",
    "            seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            detections[:,4] = detections[:,4] * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if k_idx == 0:\n",
    "                ensemble_detections.append([detections])\n",
    "            else:\n",
    "                ensemble_detections[i] += [detections]\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    case_list = ensemble_case_list\n",
    "    all_detections = ensemble_detections\n",
    "    all_annotations = ensemble_annotations\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    pid_seg_tp_score = {}\n",
    "    neg_seg_fp_score = {}\n",
    "    neg_pid_list = []\n",
    "    neg_score_list = []\n",
    "\n",
    "    for i in range(len(case_list)):\n",
    "        case_name = case_list[i]\n",
    "        seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "        if seg_anno_name not in pid_seg_tp_score:\n",
    "            pid_seg_tp_score[seg_anno_name] = {}\n",
    "\n",
    "        if seg_anno_name not in neg_seg_fp_score and seg_anno_name[0] == 'I':\n",
    "            neg_seg_fp_score[seg_anno_name] = 0\n",
    "\n",
    "        if case_name + '.npz' in SEG_anno_list:\n",
    "            SEG_anno = np.load(SEG_anno_path + case_name + '.npz')['BBOX']\n",
    "            \n",
    "        annotations = ensemble_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "        \n",
    "        detections = ensemble_detections[i]\n",
    "        detections_concat = np.concatenate(detections, axis=0)\n",
    "        \n",
    "        if len(detections_concat) == 0 and annotations.shape[0] == 0 and seg_anno_name[0] == 'I':\n",
    "            neg_pid_list.append(seg_anno_name)\n",
    "            neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        boxes_list = [each[:,:4] / 448 for each in detections]\n",
    "        scores_list = [each[:,-1] for each in detections]\n",
    "        labels_list = [np.ones_like(each[:,-1]) for each in detections]\n",
    "        weights = [1,1,1,1,1]\n",
    "        iou_thr = 0.1\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            weights=weights, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "\n",
    "        if len(detections) == 0 and annotations.shape[0] == 0 and seg_anno_name[0] == 'I':\n",
    "            neg_pid_list.append(seg_anno_name)\n",
    "            neg_score_list.append(0)\n",
    "            continue\n",
    "\n",
    "        for d in detections:\n",
    "            if d[4] < S_IOU:\n",
    "                continue\n",
    "\n",
    "            tmp_score = d[4]  * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                    neg_seg_fp_score[seg_anno_name] = max(neg_seg_fp_score[seg_anno_name], tmp_score)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU:\n",
    "                x1,y1,x2,y2 = a_tensor[assigned_annotation].data.numpy().astype('uint16')[0]\n",
    "                x_mid = (x1+x2)//2\n",
    "                y_mid = (y1+y2)//2\n",
    "\n",
    "                hit_anno = SEG_anno[y_mid, x_mid]\n",
    "                if hit_anno == 0:\n",
    "                    continue\n",
    "                elif hit_anno in Count_dict[seg_anno_name]['Hit']:\n",
    "                    continue\n",
    "                else:\n",
    "                    Count_dict[seg_anno_name]['Hit'].append(hit_anno)\n",
    "\n",
    "                if seg_anno_name[0] != 'I':\n",
    "                    hit_anno_name = str(hit_anno)\n",
    "                    if hit_anno_name not in pid_seg_tp_score[seg_anno_name]:\n",
    "                        pid_seg_tp_score[seg_anno_name][hit_anno_name] = tmp_score\n",
    "                    else:\n",
    "                        ori_score = pid_seg_tp_score[seg_anno_name][hit_anno_name]\n",
    "                        pid_seg_tp_score[seg_anno_name][hit_anno_name] = max(ori_score, tmp_score)\n",
    "            else:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                    neg_seg_fp_score[seg_anno_name] = max(neg_seg_fp_score[seg_anno_name], tmp_score)\n",
    "\n",
    "    seg_label_list = []\n",
    "    hit_label_list = []\n",
    "    for name in Count_dict:\n",
    "        seg_label_list += Count_dict[name]['GT']\n",
    "        hit_label_list += Count_dict[name]['Hit']\n",
    "\n",
    "    seg_num = len(seg_label_list)\n",
    "    hit_num = len(hit_label_list)\n",
    "\n",
    "    pos_score_list = []\n",
    "    for pid in pid_seg_tp_score:\n",
    "        for hit_anno_name in pid_seg_tp_score[pid]:\n",
    "            score = pid_seg_tp_score[pid][hit_anno_name]\n",
    "            pos_score_list.append(score)\n",
    "\n",
    "    unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "    unique_score_list.insert(0, -1)\n",
    "    unique_score_list.append(1.1)\n",
    "\n",
    "    unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "    Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "\n",
    "    sens_case_list = []\n",
    "    spec_pid_list = []\n",
    "\n",
    "    for th_score in unique_score_list:\n",
    "        TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "        sens_case = TP_case_num / seg_num\n",
    "        sens_case_list.append(sens_case)\n",
    "\n",
    "        FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "        spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "    # for sens_idx, sens in enumerate(sens_case_list):\n",
    "    #     print(sens, spec_pid_list[sens_idx])\n",
    "\n",
    "    print(seg_num, hit_num, round(hit_num / seg_num,4))\n",
    "    print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "\n",
    "    for i in sorted(list(set(seg_label_list))):\n",
    "        mat = \"{:2} {:2} {:2} {:}\"\n",
    "        hit_num = np.sum(np.array(hit_label_list)==i)\n",
    "        seg_num = np.sum(np.array(seg_label_list)==i)\n",
    "        print(mat.format(i, hit_num, seg_num, (hit_num / seg_num).round(4)))\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6),dpi=100)\n",
    "    plt.plot(spec_pid_list, sens_case_list)\n",
    "    plt.xlim(-0.1,1.1)\n",
    "    plt.ylim(-0.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "99c36d62",
   "metadata": {
    "code_folding": [
     0,
     105
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Hit IoU 0.1 =========\n",
      "mAP: 0.8489\n",
      "=========== Hit IoU 0.2 =========\n",
      "mAP: 0.8420\n",
      "=========== Hit IoU 0.3 =========\n",
      "mAP: 0.8306\n",
      "=========== Hit IoU 0.4 =========\n",
      "mAP: 0.7957\n",
      "=========== Hit IoU 0.5 =========\n",
      "mAP: 0.7150\n"
     ]
    }
   ],
   "source": [
    "for H_IOU in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    print('=========== Hit IoU %s ========='%H_IOU)\n",
    "    S_IOU = 0.05\n",
    "    NMS_IOU = 0.01\n",
    "\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "\n",
    "    ensemble_case_list = None\n",
    "    ensemble_detections = []\n",
    "    ensemble_annotations = None\n",
    "\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "\n",
    "        case_list = tmp_result_file['case']\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if k_idx == 0:\n",
    "            ensemble_case_list = case_list\n",
    "            ensemble_annotations = all_annotations\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case_name = case_list[i]\n",
    "            seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            detections[:,4] = detections[:,4] * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if k_idx == 0:\n",
    "                ensemble_detections.append([detections])\n",
    "            else:\n",
    "                ensemble_detections[i] += [detections]\n",
    "   \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    case_list = ensemble_case_list\n",
    "    all_detections = ensemble_detections\n",
    "    all_annotations = ensemble_annotations\n",
    "\n",
    "    for i in range(len(case_list)):\n",
    "        case = case_list[i]\n",
    "        pid = '_'.join(case.split('_')[:-1])\n",
    "\n",
    "        annotations = ensemble_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "\n",
    "        detections = ensemble_detections[i]\n",
    "        detections_concat = np.concatenate(detections, axis=0)\n",
    "        \n",
    "        if len(detections_concat) == 0:\n",
    "            continue\n",
    "        \n",
    "        boxes_list = [each[:,:4] / 448 for each in detections]\n",
    "        scores_list = [each[:,-1] for each in detections]\n",
    "        labels_list = [np.ones_like(each[:,-1]) for each in detections]\n",
    "        weights = [1,1,1,1,1]\n",
    "        iou_thr = 0.1\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            weights=weights, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "\n",
    "        for d in detections:\n",
    "            if d[4] < S_IOU:\n",
    "                continue\n",
    "\n",
    "            tmp_score = d[4]  * K_pid_score[str(k_idx)][pid]\n",
    "            scores = np.append(scores, tmp_score)\n",
    "\n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU and assigned_annotation not in detected_annotations:\n",
    "                false_positives = np.append(false_positives, 0)\n",
    "                true_positives = np.append(true_positives, 1)\n",
    "                detected_annotations.append(assigned_annotation)\n",
    "            else:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "\n",
    "    if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "        print('No detection')\n",
    "    else:\n",
    "        # sort by score\n",
    "        indices = np.argsort(-scores)\n",
    "        scores = scores[indices]\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "\n",
    "        anno = num_annotations\n",
    "        case_num = len(case_list)\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision = compute_ap(recall, precision)\n",
    "\n",
    "        print('mAP: {:.4f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b39af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5832c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
