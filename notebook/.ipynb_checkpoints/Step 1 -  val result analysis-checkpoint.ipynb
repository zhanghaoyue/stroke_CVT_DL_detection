{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663dd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, auc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision.ops import box_iou\n",
    "from torchvision.ops import nms\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "from ensemble_boxes import non_maximum_weighted\n",
    "\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d688cfbd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74d83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_list = [ 557,  600,  614,  547,  503]\n",
    "case_list = [1193, 1185, 1192, 1175, 1147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58425538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MCS_NL23_bs16_iou03_size448',\n",
      " 'MCS_NL3_bs16_iou03_size448',\n",
      " 'MCSdv0123_bs16_iou03_size448',\n",
      " 'MCSdv123_bs16_iou03_size448',\n",
      " 'MCSdv23_bs16_iou03_size448',\n",
      " 'MCSdv23_bs16_iou03_size896',\n",
      " 'MCSdv3_bs16_iou03_size448',\n",
      " 'MC_CO_dv0123_bs16_iou03_size448',\n",
      " 'MC_CO_dv123_bs16_iou03_size448',\n",
      " 'MC_CO_dv23_bs16_iou03_size448',\n",
      " 'MC_CO_dv3_bs16_iou03_size448',\n",
      " 'MC_SE_dv3_bs16_iou03_size896',\n",
      " 'MCpre_bs16_iou03_size672',\n",
      " 'MCpre_bs16_iou03_size896',\n",
      " 'mask_rcnn_1',\n",
      " 'mask_rcnn_FLAIR',\n",
      " 'mask_rcnn_T1',\n",
      " 'mask_rcnn_T1T2',\n",
      " 'mask_rcnn_T2',\n",
      " 'mask_rcnn_T2FLAIR',\n",
      " 'mrDS_bs16_iou03_size892',\n",
      " 'mrSAdv23_bs16_iou03_size448',\n",
      " 'mrSAdv23_bs16_iou03_size896',\n",
      " 'mrSAdv3_bs16_iou03_size448',\n",
      " 'mrSAdv3_bs16_iou03_size896',\n",
      " 'mr_bs16_iou03_size448_base1',\n",
      " 'mr_bs16_iou03_size896',\n",
      " 'mr_bs16_iou03_size896_base2',\n",
      " 'mrcls',\n",
      " 'mrcls3w01_bs16_iou03_size448',\n",
      " 'mrcls_BCE_p_w01_bs16_iou03_size448',\n",
      " 'mrcls_BCE_s_w01_bs16_iou03_size448',\n",
      " 'mrcls_CE_p_w01_bs16_iou03_size448',\n",
      " 'mrcls_CE_s_w01_bs16_iou03_size448',\n",
      " 'mrcls_bs16_iou03_size448',\n",
      " 'mrcls_dv123_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv23_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_p_w01_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_s_w001_bs16_iou03_size896',\n",
      " 'mrcls_dv3_BCE_s_w01_bs16_iou03_size896',\n",
      " 'mrpa_bs16_iou03_size448']\n"
     ]
    }
   ],
   "source": [
    "model_path = '../val_output/N4_All/'\n",
    "pprint([each for each in sorted(os.listdir(model_path))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3894dbb1",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../val_output/N4_All/mask_rcnn_FLAIR/\n"
     ]
    }
   ],
   "source": [
    "key = 'mask_rcnn_FLAIR'\n",
    "if True:\n",
    "    result_path = '../val_output/N4_All/' + key + '/'\n",
    "    print(result_path)\n",
    "    result_list = sorted([each for each in os.listdir(result_path)])\n",
    "\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "    K_pid_score = {}\n",
    "\n",
    "    for k_idx in range(0,5):\n",
    "        K_pid_score[str(k_idx)] = {}\n",
    "\n",
    "        slice_score_list = []\n",
    "        slice_label_list = []\n",
    "\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "        if len(tmp_result_npz) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            tmp_result_npz = tmp_result_npz[0]\n",
    "\n",
    "    #     print(tmp_result_npz)\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "        case_list = tmp_result_file['case']\n",
    "\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if 'cls' in key:\n",
    "            model_slice_score_list = tmp_result_file['cls_pre']\n",
    "\n",
    "        false_positives = np.zeros((0,))\n",
    "        true_positives = np.zeros((0,))\n",
    "        scores = np.zeros((0,))\n",
    "        num_annotations = 0.0\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case = case_list[i]\n",
    "            pid = '_'.join(case.split('_')[:-1])\n",
    "\n",
    "            if pid not in K_pid_score[str(k_idx)]:\n",
    "                K_pid_score[str(k_idx)][pid] = [0]\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            annotations = all_annotations[i]\n",
    "            num_annotations += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            bb_scores = torch.tensor(detections[:,4])\n",
    "            anchorBoxes = torch.tensor(detections[:,:4])\n",
    "            anchors_nms_idx = nms(anchorBoxes, bb_scores, 0.1)\n",
    "            anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "            detections = detections[anchors_nms_idx]\n",
    "\n",
    "            for d in detections:\n",
    "                det_score = d[4]\n",
    "                K_pid_score[str(k_idx)][pid] += [det_score]\n",
    "\n",
    "            try:\n",
    "                slice_score_list.append(np.max(detections[:,4]))\n",
    "            except:\n",
    "                slice_score_list.append(0)\n",
    "            slice_label_list.append(int(annotations.shape[0] != 0))\n",
    "\n",
    "        for pid, score_list in K_pid_score[str(k_idx)].items():\n",
    "            K_pid_score[str(k_idx)][pid] = np.mean(sorted(score_list)[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04b36d70",
   "metadata": {
    "code_folding": [
     6
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.7609\n",
      "Precision: 0.6454\n",
      "Recall: 0.8007\n",
      "F1-Score: 0.7147\n",
      "0.8101470560239363 - 0.050 0.5832\n",
      "0.7181858905182447 - 0.125 0.7199\n",
      "0.5067651407610091 - 0.250 0.8089\n",
      "0.21461580121393986 - 0.500 0.8699\n",
      "0.024308483411966675 - 1.000 0.911\n",
      "Mean: 0.7786\n",
      "AFROC: 0.7529\n",
      "========================================\n",
      "mAP: 0.7586\n",
      "Precision: 0.6942\n",
      "Recall: 0.8025\n",
      "F1-Score: 0.7445\n",
      "0.8792858596686699 - 0.050 0.4857\n",
      "0.7740593789429416 - 0.125 0.6943\n",
      "0.4238541201438384 - 0.250 0.8535\n",
      "0.07528586489281563 - 0.500 0.922\n",
      "0.024394299285527575 - 1.000 0.9268\n",
      "Mean: 0.7764\n",
      "AFROC: 0.7545\n",
      "========================================\n",
      "mAP: 0.8054\n",
      "Precision: 0.7646\n",
      "Recall: 0.8009\n",
      "F1-Score: 0.7823\n",
      "0.7628433459493422 - 0.050 0.6217\n",
      "0.5316826802412061 - 0.125 0.7795\n",
      "0.203974657692795 - 0.250 0.8622\n",
      "0.03215996979827788 - 0.500 0.9081\n",
      "0.007128141358262605 - 1.000 0.9081\n",
      "Mean: 0.8159\n",
      "AFROC: 0.7717\n",
      "========================================\n",
      "mAP: 0.7461\n",
      "Precision: 0.6224\n",
      "Recall: 0.8040\n",
      "F1-Score: 0.7017\n",
      "0.8132457355365096 - 0.050 0.4942\n",
      "0.6664197961027689 - 0.125 0.6524\n",
      "0.42654213447989164 - 0.250 0.799\n",
      "0.12728915210574954 - 0.500 0.8962\n",
      "0.013310547553963659 - 1.000 0.9176\n",
      "Mean: 0.7519\n",
      "AFROC: 0.7639\n",
      "========================================\n",
      "mAP: 0.7562\n",
      "Precision: 0.6903\n",
      "Recall: 0.8000\n",
      "F1-Score: 0.7411\n",
      "0.9539218422828242 - 0.050 0.5514\n",
      "0.8079725464920291 - 0.125 0.7551\n",
      "0.3708236227304482 - 0.250 0.8467\n",
      "0.06382245433412 - 0.500 0.9065\n",
      "0.010181260034043996 - 1.000 0.9103\n",
      "Mean: 0.794\n",
      "AFROC: 0.7958\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.1\n",
    "CLS_th = 0.01\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "for k_idx in range(0,5):\n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "    \n",
    "    if len(tmp_result_npz) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        tmp_result_npz = tmp_result_npz[0]\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "\n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    pos_pid_list = []\n",
    "    neg_pid_list = []\n",
    "    pos_score_list = []\n",
    "    neg_score_list = []\n",
    "\n",
    "    for i in range(len(case_list)):\n",
    "        case_name = case_list[i]\n",
    "        seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "        \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "  \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        boxes_list = [detections[:,:4] / 448]\n",
    "        scores_list = [detections[:,-1]]\n",
    "        labels_list = np.ones_like(scores_list)\n",
    "    \n",
    "        iou_thr = NMS_IOU\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "        \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        detections = np.array(sorted(detections.tolist(), key=lambda x:x[-1], reverse=True))\n",
    "\n",
    "        for d in detections:\n",
    "            tmp_score = d[4]\n",
    "            \n",
    "            if tmp_score < S_IOU:\n",
    "                continue\n",
    "            \n",
    "            tmp_score = tmp_score * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "            scores = np.append(scores, tmp_score)\n",
    "            \n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                \n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU:\n",
    "                if assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                    \n",
    "                    if seg_anno_name[0] != 'I':\n",
    "                        pos_pid_list.append(seg_anno_name)\n",
    "                        pos_score_list.append(tmp_score)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "            else:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "    \n",
    "    anno_list[k_idx] = num_annotations\n",
    "    if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "        print('No detection')\n",
    "    else:\n",
    "        # sort by score\n",
    "        indices = np.argsort(-scores)\n",
    "        scores = scores[indices]\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "        \n",
    "        anno = num_annotations\n",
    "        case_num = len(case_list)\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "        \n",
    "        # compute average precision\n",
    "        average_precision = compute_ap(recall, precision)\n",
    "        \n",
    "        recall_copy = deepcopy(recall)\n",
    "        recall_copy[recall_copy < 0.8] = 0\n",
    "        recall_th_idx = np.argmin(np.abs(recall_copy - 0.8))\n",
    "        \n",
    "        recall_max = recall[recall_th_idx]\n",
    "        precision_max = precision[recall_th_idx]\n",
    "        while precision[recall_th_idx] >= precision_max:\n",
    "            recall_th_idx += 1\n",
    "            \n",
    "        recall = recall[recall_th_idx]\n",
    "        precision = precision[recall_th_idx]\n",
    "\n",
    "        print('mAP: {:.4f}'.format(average_precision))\n",
    "        print(\"Precision: {:.4f}\".format(precision))\n",
    "        print(\"Recall: {:.4f}\".format(recall))\n",
    "        print(\"F1-Score: {:.4f}\".format(2*recall*precision/(recall+precision)))\n",
    "\n",
    "        fp_list = false_positives\n",
    "        tp_list = true_positives\n",
    "        \n",
    "        fps_list = []\n",
    "        \n",
    "        for th in [0.05, 0.125, 0.25, 0.5, 1]:\n",
    "            fp_th_idx = np.argmin(np.abs(fp_list / case_num - th))\n",
    "            tp_th = tp_list[fp_th_idx]\n",
    "            print('%s - %1.3f'%(scores[fp_th_idx], th), (tp_th / anno).round(4))\n",
    "            fps_list.append(tp_th / anno)\n",
    "        print('Mean:', np.mean(fps_list).round(4))\n",
    "    \n",
    "    unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "    unique_score_list.insert(0, -1)\n",
    "    unique_score_list.append(1.1)\n",
    "    \n",
    "    unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "    Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "\n",
    "    sens_case_list = []\n",
    "    spec_pid_list = []\n",
    "\n",
    "    for th_score in unique_score_list:\n",
    "        TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "        sens_case = TP_case_num / num_annotations\n",
    "        sens_case_list.append(sens_case)\n",
    "        \n",
    "        FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "        spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "#     for sens_idx, sens in enumerate(sens_case_list):\n",
    "#         print(sens, spec_pid_list[sens_idx])\n",
    "    \n",
    "    \n",
    "#     fig = plt.figure(figsize=(10,10),dpi=100)\n",
    "#     plt.plot(spec_pid_list, sens_case_list)\n",
    "#     plt.xlim(-0.1,1.1)\n",
    "#     plt.ylim(-0.1,1.1)\n",
    "#     plt.show()\n",
    "#     break\n",
    "    \n",
    "    print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "    print('========================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e52b6ad1",
   "metadata": {
    "code_folding": [
     30
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.7358\n",
      "Precision: 0.6800\n",
      "Recall: 0.8003\n",
      "F1-Score: 0.7353\n",
      "0.9551733808196516 - 0.050 0.1188\n",
      "0.906838733290467 - 0.125 0.3092\n",
      "0.8586307746074269 - 0.250 0.4957\n",
      "0.7649010526291988 - 0.500 0.6637\n",
      "0.5234570145695727 - 1.000 0.8013\n",
      "Mean: 0.4778\n",
      "AFROC: 0.7488\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.1\n",
    "CLS_th = 0.01\n",
    "\n",
    "false_positives = np.zeros((0,))\n",
    "true_positives = np.zeros((0,))\n",
    "scores = np.zeros((0,))\n",
    "num_annotations = 0.0\n",
    "case_num = 0\n",
    "\n",
    "pos_pid_list = []\n",
    "neg_pid_list = []\n",
    "pos_score_list = []\n",
    "neg_score_list = []\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "for k_idx in range(0,5):\n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "    \n",
    "    if len(tmp_result_npz) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        tmp_result_npz = tmp_result_npz[0]\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "    case_num += len(case_list)\n",
    "    \n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    for i in range(len(case_list)):\n",
    "        case_name = case_list[i]\n",
    "        seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "        \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "  \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        boxes_list = [detections[:,:4] / 448]\n",
    "        scores_list = [detections[:,-1]]\n",
    "        labels_list = np.ones_like(scores_list)\n",
    "    \n",
    "        iou_thr = NMS_IOU\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "        \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "        detections = np.array(sorted(detections.tolist(), key=lambda x:x[-1], reverse=True))\n",
    "\n",
    "        for d in detections:\n",
    "            tmp_score = d[4]\n",
    "            \n",
    "            if tmp_score < S_IOU:\n",
    "                continue\n",
    "            \n",
    "            tmp_score = tmp_score * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "            scores = np.append(scores, tmp_score)\n",
    "            \n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                \n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU:\n",
    "                if assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                    \n",
    "                    if seg_anno_name[0] != 'I':\n",
    "                        pos_pid_list.append(seg_anno_name)\n",
    "                        pos_score_list.append(tmp_score)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "            else:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "    \n",
    "if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "    print('No detection')\n",
    "else:\n",
    "    # sort by score\n",
    "    indices = np.argsort(-scores)\n",
    "    scores = scores[indices]\n",
    "    false_positives = false_positives[indices]\n",
    "    true_positives = true_positives[indices]\n",
    "\n",
    "    anno = num_annotations\n",
    "    case_num = len(case_list)\n",
    "\n",
    "    # compute false positives and true positives\n",
    "    false_positives = np.cumsum(false_positives)\n",
    "    true_positives = np.cumsum(true_positives)\n",
    "\n",
    "    # compute recall and precision\n",
    "    recall = true_positives / num_annotations\n",
    "    precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "    # compute average precision\n",
    "    average_precision = compute_ap(recall, precision)\n",
    "\n",
    "    recall_copy = deepcopy(recall)\n",
    "    recall_copy[recall_copy < 0.8] = 0\n",
    "    recall_th_idx = np.argmin(np.abs(recall_copy - 0.8))\n",
    "\n",
    "    recall_max = recall[recall_th_idx]\n",
    "    precision_max = precision[recall_th_idx]\n",
    "    while precision[recall_th_idx] >= precision_max:\n",
    "        recall_th_idx += 1\n",
    "\n",
    "    recall = recall[recall_th_idx]\n",
    "    precision = precision[recall_th_idx]\n",
    "\n",
    "    print('mAP: {:.4f}'.format(average_precision))\n",
    "    print(\"Precision: {:.4f}\".format(precision))\n",
    "    print(\"Recall: {:.4f}\".format(recall))\n",
    "    print(\"F1-Score: {:.4f}\".format(2*recall*precision/(recall+precision)))\n",
    "\n",
    "    fp_list = false_positives\n",
    "    tp_list = true_positives\n",
    "\n",
    "    fps_list = []\n",
    "\n",
    "    for th in [0.05, 0.125, 0.25, 0.5, 1]:\n",
    "        fp_th_idx = np.argmin(np.abs(fp_list / case_num - th))\n",
    "        tp_th = tp_list[fp_th_idx]\n",
    "        print('%s - %1.3f'%(scores[fp_th_idx], th), (tp_th / anno).round(4))\n",
    "        fps_list.append(tp_th / anno)\n",
    "    print('Mean:', np.mean(fps_list).round(4))\n",
    "\n",
    "unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "unique_score_list.insert(0, -1)\n",
    "unique_score_list.append(1.1)\n",
    "\n",
    "unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "\n",
    "sens_case_list = []\n",
    "spec_pid_list = []\n",
    "\n",
    "for th_score in unique_score_list:\n",
    "    TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "    sens_case = TP_case_num / num_annotations\n",
    "    sens_case_list.append(sens_case)\n",
    "\n",
    "    FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "    spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "#     for sens_idx, sens in enumerate(sens_case_list):\n",
    "#         print(sens, spec_pid_list[sens_idx])\n",
    "\n",
    "\n",
    "#     fig = plt.figure(figsize=(10,10),dpi=100)\n",
    "#     plt.plot(spec_pid_list, sens_case_list)\n",
    "#     plt.xlim(-0.1,1.1)\n",
    "#     plt.ylim(-0.1,1.1)\n",
    "#     plt.show()\n",
    "#     break\n",
    "\n",
    "print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "print('========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c6ae2",
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.01\n",
    "top = 3\n",
    "th = 0.7\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "for k_idx in range(0,5):\n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "    if len(tmp_result_npz) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        tmp_result_npz = tmp_result_npz[0]\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "\n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    pid_dict = {}\n",
    "\n",
    "    for i in range(len(case_list)):\n",
    "        case = case_list[i]\n",
    "        pid = '_'.join(case.split('_')[:-1])\n",
    "        \n",
    "        if pid not in pid_dict:\n",
    "            pid_dict[pid] = [0]\n",
    "        \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "        \n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "#         bb_scores = torch.tensor(detections[:,4])\n",
    "#         anchorBoxes = torch.tensor(detections[:,:4])\n",
    "#         anchors_nms_idx = nms(anchorBoxes, bb_scores, NMS_IOU)\n",
    "#         anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "#         detections = detections[anchors_nms_idx]\n",
    "        \n",
    "        boxes_list = [detections[:,:4] / 448]\n",
    "        scores_list = [detections[:,-1]]\n",
    "        labels_list = np.ones_like(scores_list)\n",
    "    \n",
    "        iou_thr = NMS_IOU\n",
    "        skip_box_thr = 0.0001\n",
    "        \n",
    "        boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            iou_thr=iou_thr,\n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "        \n",
    "        boxes = boxes * 448\n",
    "        nms_scores = nms_scores[:,np.newaxis]\n",
    "        detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "        \n",
    "        for d in detections:\n",
    "            det_score = d[4] * K_pid_score[str(k_idx)][pid]\n",
    "            pid_dict[pid] += [det_score]\n",
    "\n",
    "    score_list = []\n",
    "    label_list = []\n",
    "    for pid in pid_dict:\n",
    "        if pid[:2] == 'I_':\n",
    "            label_list.append(0)\n",
    "        else:\n",
    "            label_list.append(1)\n",
    "        score_list.append(np.mean(sorted(pid_dict[pid], reverse=True)[:top]))\n",
    "        \n",
    "    score_list = np.array(score_list)\n",
    "    label_list = np.array(label_list)\n",
    "    \n",
    "    print(round(roc_auc_score(label_list, score_list),4))\n",
    "    print(round(accuracy_score(label_list, score_list>th),4))\n",
    "    print(round(recall_score(label_list, score_list>th),4))\n",
    "    print(round(recall_score(1-label_list, score_list<=th),4))\n",
    "    print('======================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c36d62",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for H_IOU in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    print('=========== Hit IoU %s ========='%H_IOU)\n",
    "    S_IOU = 0.05\n",
    "    NMS_IOU = 0.01\n",
    "\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)]\n",
    "        if len(tmp_result_npz) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            tmp_result_npz = tmp_result_npz[0]\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "        case_list = tmp_result_file['case']\n",
    "\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        false_positives = np.zeros((0,))\n",
    "        true_positives = np.zeros((0,))\n",
    "        scores = np.zeros((0,))\n",
    "        num_annotations = 0.0\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case = case_list[i]\n",
    "            pid = '_'.join(case.split('_')[:-1])\n",
    "            \n",
    "            detections = all_detections[i]\n",
    "            annotations = all_annotations[i]\n",
    "            num_annotations += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            boxes_list = [detections[:,:4] / 448]\n",
    "            scores_list = [detections[:,-1]]\n",
    "            labels_list = np.ones_like(scores_list)\n",
    "\n",
    "            iou_thr = NMS_IOU\n",
    "            skip_box_thr = 0.0001\n",
    "\n",
    "            boxes, nms_scores, labels = non_maximum_weighted(boxes_list, \n",
    "                                                scores_list, \n",
    "                                                labels_list, \n",
    "                                                iou_thr=iou_thr,\n",
    "                                                skip_box_thr=skip_box_thr)\n",
    "\n",
    "            boxes = boxes * 448\n",
    "            nms_scores = nms_scores[:,np.newaxis]\n",
    "            detections = np.concatenate([boxes, nms_scores], axis=1)\n",
    "\n",
    "            for d in detections:\n",
    "                if d[4] < S_IOU:\n",
    "                    continue\n",
    "                \n",
    "                tmp_score = d[4]  * K_pid_score[str(k_idx)][pid]\n",
    "                scores = np.append(scores, tmp_score)\n",
    "\n",
    "                if annotations.shape[0] == 0:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "                    continue\n",
    "\n",
    "                d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "                a_tensor = torch.tensor(annotations)\n",
    "                overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "                if max_overlap >= H_IOU and assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "\n",
    "        if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "            print('No detection')\n",
    "        else:\n",
    "            # sort by score\n",
    "            indices = np.argsort(-scores)\n",
    "            scores = scores[indices]\n",
    "            false_positives = false_positives[indices]\n",
    "            true_positives = true_positives[indices]\n",
    "\n",
    "            anno = num_annotations\n",
    "            case_num = len(case_list)\n",
    "\n",
    "            # compute false positives and true positives\n",
    "            false_positives = np.cumsum(false_positives)\n",
    "            true_positives = np.cumsum(true_positives)\n",
    "\n",
    "            # compute recall and precision\n",
    "            recall = true_positives / num_annotations\n",
    "            precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "            # compute average precision\n",
    "            average_precision = compute_ap(recall, precision)\n",
    "\n",
    "            print('mAP: {:.4f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d86c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aead641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e4ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
