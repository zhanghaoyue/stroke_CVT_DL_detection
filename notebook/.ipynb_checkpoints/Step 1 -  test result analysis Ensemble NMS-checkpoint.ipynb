{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663dd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, auc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision.ops import box_iou, nms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688cfbd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8820ba7",
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "SEG_anno_path = '../data/N4_SEG_img/'\n",
    "SEG_anno_list = sorted(os.listdir(SEG_anno_path))\n",
    "\n",
    "seg_count_dict = {}\n",
    "\n",
    "for seg_anno in tqdm(SEG_anno_list):\n",
    "    seg_anno_name = '_'.join(seg_anno.split('_')[:-1])\n",
    "    if seg_anno_name not in seg_count_dict:\n",
    "        seg_count_dict[seg_anno_name] = {'GT':[],\n",
    "                                         'Hit':[]}\n",
    "    seg_anno_array = np.load(SEG_anno_path + seg_anno)['BBOX']\n",
    "    seg_anno_label_list = np.unique(seg_anno_array).tolist()\n",
    "    for anno_label in seg_anno_label_list:\n",
    "        if anno_label == 0:\n",
    "            continue\n",
    "        elif anno_label in seg_count_dict[seg_anno_name]['GT']:\n",
    "            continue\n",
    "        else:\n",
    "            seg_count_dict[seg_anno_name]['GT'].append(anno_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_list = [ 592]\n",
    "case_list = [2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58425538",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../test_output/N4_All/'\n",
    "pprint([each for each in sorted(os.listdir(model_path))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'mrSAdv3_bs32_iou03_size448'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93705548",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = '../test_output/N4_All/' + key + '/'\n",
    "print(result_path)\n",
    "result_list = sorted([each for each in os.listdir(result_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e63d0",
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "NMS_IOU = 0.01\n",
    "\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "K_pid_score = {}\n",
    "\n",
    "for k_idx in range(0,5):\n",
    "    K_pid_score[str(k_idx)] = {}\n",
    "    \n",
    "    tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "    print(tmp_result_npz)\n",
    "    tmp_result_path = result_path + tmp_result_npz\n",
    "    tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "    case_list = tmp_result_file['case']\n",
    "\n",
    "    all_detections = tmp_result_file['det']\n",
    "    all_annotations = tmp_result_file['anno']\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "    \n",
    "    for i in range(len(case_list)):\n",
    "        case = case_list[i]\n",
    "        pid = '_'.join(case.split('_')[:-1])\n",
    "        \n",
    "        if pid not in K_pid_score[str(k_idx)]:\n",
    "            K_pid_score[str(k_idx)][pid] = [0]\n",
    "        \n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "        \n",
    "        bb_scores = torch.tensor(detections[:,4])\n",
    "        anchorBoxes = torch.tensor(detections[:,:4])\n",
    "        anchors_nms_idx = nms(anchorBoxes, bb_scores, 0.1)\n",
    "        anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "        detections = detections[anchors_nms_idx]\n",
    "        \n",
    "        for d in detections:\n",
    "            det_score = d[4]\n",
    "            K_pid_score[str(k_idx)][pid] += [det_score]\n",
    "    \n",
    "    for pid, score_list in K_pid_score[str(k_idx)].items():\n",
    "        K_pid_score[str(k_idx)][pid] = np.mean(sorted(score_list)[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b36d70",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.01\n",
    "if True:\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "\n",
    "    ensemble_case_list = None\n",
    "    ensemble_detections = []\n",
    "    ensemble_annotations = None\n",
    "\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "        print(tmp_result_npz)\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "\n",
    "        case_list = tmp_result_file['case']\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if k_idx == 0:\n",
    "            ensemble_case_list = case_list\n",
    "            ensemble_annotations = all_annotations\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case_name = case_list[i]\n",
    "            seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            detections[:,4] = detections[:,4] * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if k_idx == 0:\n",
    "                ensemble_detections.append([detections])\n",
    "            else:\n",
    "                ensemble_detections[i] += [detections]\n",
    "    for i in range(len(case_list)):\n",
    "        ensemble_detections[i] = np.concatenate(ensemble_detections[i], axis=0)\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    pos_pid_list = []\n",
    "    neg_pid_list = []\n",
    "    pos_score_list = []\n",
    "    neg_score_list = []\n",
    "\n",
    "    for i in range(len(ensemble_case_list)):\n",
    "        case_name = ensemble_case_list[i]\n",
    "        seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "        detections = ensemble_detections[i]\n",
    "        annotations = ensemble_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "\n",
    "        bb_scores = torch.tensor(detections[:,4])\n",
    "        anchorBoxes = torch.tensor(detections[:,:4])\n",
    "        anchors_nms_idx = nms(anchorBoxes, bb_scores, NMS_IOU)\n",
    "        anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "        detections = detections[anchors_nms_idx]\n",
    "\n",
    "        if len(detections) == 0:\n",
    "            if annotations.shape[0] == 0:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(0)\n",
    "            continue\n",
    "\n",
    "        detections = np.array(sorted(detections.tolist(), key=lambda x:x[-1], reverse=True))\n",
    "\n",
    "        for d in detections:\n",
    "            if d[4] < S_IOU:\n",
    "                continue\n",
    "\n",
    "            tmp_score = d[4]# * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "            scores = np.append(scores, tmp_score)\n",
    "\n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU:\n",
    "                if assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "\n",
    "                    if seg_anno_name[0] != 'I':\n",
    "                        pos_pid_list.append(seg_anno_name)\n",
    "                        pos_score_list.append(tmp_score)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives = np.append(true_positives, 0)\n",
    "            else:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "\n",
    "    if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "        print('No detection')\n",
    "    else:\n",
    "        # sort by score\n",
    "        indices = np.argsort(-scores)\n",
    "        scores = scores[indices]\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "\n",
    "        anno = num_annotations\n",
    "        case_num = len(case_list)\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision = compute_ap(recall, precision)\n",
    "\n",
    "        recall_copy = deepcopy(recall)\n",
    "        recall_copy[recall_copy < 0.8] = 0\n",
    "        recall_th_idx = np.argmin(np.abs(recall_copy - 0.8))\n",
    "\n",
    "        recall_max = recall[recall_th_idx]\n",
    "        precision_max = precision[recall_th_idx]\n",
    "        while precision[recall_th_idx] >= precision_max:\n",
    "            recall_th_idx += 1\n",
    "\n",
    "        recall = recall[recall_th_idx]\n",
    "        precision = precision[recall_th_idx]\n",
    "\n",
    "        print('mAP: {:.4f}'.format(average_precision))\n",
    "        print(\"Precision: {:.4f}\".format(precision))\n",
    "        print(\"Recall: {:.4f}\".format(recall))\n",
    "        print(\"F1-Score: {:.4f}\".format(2*recall*precision/(recall+precision)))\n",
    "\n",
    "        fp_list = false_positives\n",
    "        tp_list = true_positives\n",
    "\n",
    "        fps_list = []\n",
    "\n",
    "        for th in [0.05, 0.125, 0.25, 0.5, 1]:\n",
    "            fp_th_idx = np.argmin(np.abs(fp_list / case_num - th))\n",
    "            tp_th = tp_list[fp_th_idx]\n",
    "            print('%s - %1.3f'%(scores[fp_th_idx], th), (tp_th / anno).round(4))\n",
    "            fps_list.append(tp_th / anno)\n",
    "        print('Mean:', np.mean(fps_list).round(4))\n",
    "\n",
    "    unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "    unique_score_list.insert(0, -1)\n",
    "    unique_score_list.append(1.1)\n",
    "\n",
    "    unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "    Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "\n",
    "    sens_case_list = []\n",
    "    spec_pid_list = []\n",
    "\n",
    "    for th_score in unique_score_list:\n",
    "        TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "        sens_case = TP_case_num / num_annotations\n",
    "        sens_case_list.append(sens_case)\n",
    "\n",
    "        FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "        spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "    print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "    print('========================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282b5ac",
   "metadata": {
    "code_folding": [
     4,
     11,
     46
    ]
   },
   "outputs": [],
   "source": [
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.1\n",
    "th = 0.8\n",
    "\n",
    "if True:\n",
    "    result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "\n",
    "    ensemble_case_list = None\n",
    "    ensemble_detections = []\n",
    "    ensemble_annotations = None\n",
    "\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "        print(tmp_result_npz)\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "\n",
    "        case_list = tmp_result_file['case']\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if k_idx == 0:\n",
    "            ensemble_case_list = case_list\n",
    "            ensemble_annotations = all_annotations\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case_name = case_list[i]\n",
    "            seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            detections[:,4] = detections[:,4] * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if k_idx == 0:\n",
    "                ensemble_detections.append([detections])\n",
    "            else:\n",
    "                ensemble_detections[i] += [detections]\n",
    "    for i in range(len(case_list)):\n",
    "        ensemble_detections[i] = np.concatenate(ensemble_detections[i], axis=0)\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    pid_dict = {}\n",
    "\n",
    "    for i in range(len(ensemble_case_list)):\n",
    "        case = ensemble_case_list[i]\n",
    "        pid = '_'.join(case.split('_')[:-1])\n",
    "\n",
    "        if pid not in pid_dict:\n",
    "            pid_dict[pid] = 0\n",
    "\n",
    "        detections = ensemble_detections[i]\n",
    "        annotations = ensemble_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "        detected_annotations = []\n",
    "\n",
    "        bb_scores = torch.tensor(detections[:,4])\n",
    "        anchorBoxes = torch.tensor(detections[:,:4])\n",
    "        anchors_nms_idx = nms(anchorBoxes, bb_scores, 0.1)\n",
    "        anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "        detections = detections[anchors_nms_idx]\n",
    "\n",
    "        for d in detections:\n",
    "            det_score = d[4]\n",
    "            pid_dict[pid] = max(pid_dict[pid], det_score)\n",
    "\n",
    "    score_list = []\n",
    "    label_list = []\n",
    "    for pid in pid_dict:\n",
    "        if pid[:2] == 'I_':\n",
    "            label_list.append(0)\n",
    "        else:\n",
    "            label_list.append(1)\n",
    "        score_list.append(pid_dict[pid])\n",
    "\n",
    "    score_list = np.array(score_list)\n",
    "    label_list = np.array(label_list)\n",
    "\n",
    "    print(round(roc_auc_score(label_list, score_list),4))\n",
    "    print(round(accuracy_score(label_list, score_list>th),4))\n",
    "    print(round(recall_score(label_list, score_list>th),4))\n",
    "    print(round(recall_score(1-label_list, score_list<=th),4))\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d86c7b",
   "metadata": {
    "code_folding": [
     11
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "S_IOU = 0.05\n",
    "H_IOU = 0.3\n",
    "NMS_IOU = 0.01\n",
    "    \n",
    "Count_dict = deepcopy(seg_count_dict)\n",
    "result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "\n",
    "ensemble_case_list = None\n",
    "ensemble_detections = []\n",
    "ensemble_annotations = None\n",
    "\n",
    "if True:\n",
    "    for k_idx in range(0,5):\n",
    "        tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "        tmp_result_path = result_path + tmp_result_npz\n",
    "        tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "\n",
    "        case_list = tmp_result_file['case']\n",
    "        all_detections = tmp_result_file['det']\n",
    "        all_annotations = tmp_result_file['anno']\n",
    "\n",
    "        if k_idx == 0:\n",
    "            ensemble_case_list = case_list\n",
    "            ensemble_annotations = all_annotations\n",
    "\n",
    "        for i in range(len(case_list)):\n",
    "            case_name = case_list[i]\n",
    "            seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "            detections = all_detections[i]\n",
    "            detections[:,4] = detections[:,4] * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if k_idx == 0:\n",
    "                ensemble_detections.append([detections])\n",
    "            else:\n",
    "                ensemble_detections[i] += [detections]\n",
    "\n",
    "    for i in range(len(case_list)):\n",
    "        ensemble_detections[i] = np.concatenate(ensemble_detections[i], axis=0)\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    case_list = ensemble_case_list\n",
    "    all_detections = ensemble_detections\n",
    "    all_annotations = ensemble_annotations\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives = np.zeros((0,))\n",
    "    scores = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    pid_seg_tp_score = {}\n",
    "    neg_seg_fp_score = {}\n",
    "    neg_pid_list = []\n",
    "    neg_score_list = []\n",
    "\n",
    "    for i in range(len(case_list)):\n",
    "        case_name = case_list[i]\n",
    "        seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "        if seg_anno_name not in pid_seg_tp_score:\n",
    "            pid_seg_tp_score[seg_anno_name] = {}\n",
    "\n",
    "        if seg_anno_name not in neg_seg_fp_score and seg_anno_name[0] == 'I':\n",
    "            neg_seg_fp_score[seg_anno_name] = 0\n",
    "\n",
    "        if case_name + '.npz' in SEG_anno_list:\n",
    "            SEG_anno = np.load(SEG_anno_path + case_name + '.npz')['BBOX']\n",
    "\n",
    "        detections = all_detections[i]\n",
    "        annotations = all_annotations[i]\n",
    "        num_annotations += annotations.shape[0]\n",
    "\n",
    "        bb_scores = torch.tensor(detections[:,4])\n",
    "        anchorBoxes = torch.tensor(detections[:,:4])\n",
    "        anchors_nms_idx = nms(anchorBoxes, bb_scores, NMS_IOU)\n",
    "        anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "        detections = detections[anchors_nms_idx]\n",
    "\n",
    "        if len(detections) == 0 and annotations.shape[0] == 0 and seg_anno_name[0] == 'I':\n",
    "            neg_pid_list.append(seg_anno_name)\n",
    "            neg_score_list.append(0)\n",
    "            continue\n",
    "\n",
    "        for d in detections:\n",
    "            if d[4] < S_IOU:\n",
    "                continue\n",
    "\n",
    "            tmp_score = d[4]  * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "            if annotations.shape[0] == 0:\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives = np.append(true_positives, 0)\n",
    "\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                    neg_seg_fp_score[seg_anno_name] = max(neg_seg_fp_score[seg_anno_name], tmp_score)\n",
    "                continue\n",
    "\n",
    "            d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "            a_tensor = torch.tensor(annotations)\n",
    "            overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "            if max_overlap >= H_IOU:\n",
    "                x1,y1,x2,y2 = a_tensor[assigned_annotation].data.numpy().astype('uint16')[0]\n",
    "                x_mid = (x1+x2)//2\n",
    "                y_mid = (y1+y2)//2\n",
    "\n",
    "                hit_anno = SEG_anno[y_mid, x_mid]\n",
    "                if hit_anno == 0:\n",
    "                    continue\n",
    "                elif hit_anno in Count_dict[seg_anno_name]['Hit']:\n",
    "                    continue\n",
    "                else:\n",
    "                    Count_dict[seg_anno_name]['Hit'].append(hit_anno)\n",
    "\n",
    "                if seg_anno_name[0] != 'I':\n",
    "                    hit_anno_name = str(hit_anno)\n",
    "                    if hit_anno_name not in pid_seg_tp_score[seg_anno_name]:\n",
    "                        pid_seg_tp_score[seg_anno_name][hit_anno_name] = tmp_score\n",
    "                    else:\n",
    "                        ori_score = pid_seg_tp_score[seg_anno_name][hit_anno_name]\n",
    "                        pid_seg_tp_score[seg_anno_name][hit_anno_name] = max(ori_score, tmp_score)\n",
    "            else:\n",
    "                if seg_anno_name[0] == 'I':\n",
    "                    neg_pid_list.append(seg_anno_name)\n",
    "                    neg_score_list.append(tmp_score)\n",
    "                    neg_seg_fp_score[seg_anno_name] = max(neg_seg_fp_score[seg_anno_name], tmp_score)\n",
    "\n",
    "    seg_label_list = []\n",
    "    hit_label_list = []\n",
    "    for name in Count_dict:\n",
    "        seg_label_list += Count_dict[name]['GT']\n",
    "        hit_label_list += Count_dict[name]['Hit']\n",
    "\n",
    "    seg_num = len(seg_label_list)\n",
    "    hit_num = len(hit_label_list)\n",
    "\n",
    "    pos_score_list = []\n",
    "    for pid in pid_seg_tp_score:\n",
    "        for hit_anno_name in pid_seg_tp_score[pid]:\n",
    "            score = pid_seg_tp_score[pid][hit_anno_name]\n",
    "            pos_score_list.append(score)\n",
    "\n",
    "    unique_score_list = sorted(list(set(pos_score_list + neg_score_list)))\n",
    "    unique_score_list.insert(0, -1)\n",
    "    unique_score_list.append(1.1)\n",
    "\n",
    "    unique_pid_list = np.unique(np.array(neg_pid_list).tolist())\n",
    "    Neg_pid_num = len(np.unique(np.array(neg_pid_list).tolist()))\n",
    "\n",
    "    sens_case_list = []\n",
    "    spec_pid_list = []\n",
    "\n",
    "    for th_score in unique_score_list:\n",
    "        TP_case_num = np.sum(np.array(pos_score_list) > th_score)\n",
    "        sens_case = TP_case_num / seg_num\n",
    "        sens_case_list.append(sens_case)\n",
    "\n",
    "        FP_pid_num = len(np.unique(np.array(neg_pid_list)[np.array(neg_score_list) > th_score]).tolist())\n",
    "        spec_pid_list.append(FP_pid_num/Neg_pid_num)\n",
    "\n",
    "    # for sens_idx, sens in enumerate(sens_case_list):\n",
    "    #     print(sens, spec_pid_list[sens_idx])\n",
    "\n",
    "    print(seg_num, hit_num, round(hit_num / seg_num,4))\n",
    "    print('AFROC:', auc(spec_pid_list, sens_case_list).round(4))\n",
    "\n",
    "    for i in sorted(list(set(seg_label_list))):\n",
    "        mat = \"{:2} {:2} {:2} {:}\"\n",
    "        hit_num = np.sum(np.array(hit_label_list)==i)\n",
    "        seg_num = np.sum(np.array(seg_label_list)==i)\n",
    "        print(mat.format(i, hit_num, seg_num, (hit_num / seg_num).round(4)))\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6),dpi=100)\n",
    "    plt.plot(spec_pid_list, sens_case_list)\n",
    "    plt.xlim(-0.1,1.1)\n",
    "    plt.ylim(-0.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c36d62",
   "metadata": {
    "code_folding": [
     0,
     11,
     36,
     48,
     91
    ]
   },
   "outputs": [],
   "source": [
    "# for H_IOU in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "#     print('=========== Hit IoU %s ========='%H_IOU)\n",
    "#     S_IOU = 0.05\n",
    "#     NMS_IOU = 0.01\n",
    "\n",
    "#     result_list = sorted([each for each in os.listdir(result_path) if each[0] == 'K'])\n",
    "\n",
    "#     ensemble_case_list = None\n",
    "#     ensemble_detections = []\n",
    "#     ensemble_annotations = None\n",
    "\n",
    "#     for k_idx in range(0,5):\n",
    "#         tmp_result_npz = [each for each in result_list if each.startswith('K%s'%k_idx)][0]\n",
    "#         tmp_result_path = result_path + tmp_result_npz\n",
    "#         tmp_result_file = np.load(tmp_result_path, allow_pickle=True)\n",
    "\n",
    "#         case_list = tmp_result_file['case']\n",
    "#         all_detections = tmp_result_file['det']\n",
    "#         all_annotations = tmp_result_file['anno']\n",
    "\n",
    "#         if k_idx == 0:\n",
    "#             ensemble_case_list = case_list\n",
    "#             ensemble_annotations = all_annotations\n",
    "\n",
    "#         for i in range(len(case_list)):\n",
    "#             case_name = case_list[i]\n",
    "#             seg_anno_name = '_'.join(case_name.split('_')[:-1])\n",
    "\n",
    "#             detections = all_detections[i]\n",
    "#             detections[:,4] = detections[:,4] * K_pid_score[str(k_idx)][seg_anno_name]\n",
    "\n",
    "#             if k_idx == 0:\n",
    "#                 ensemble_detections.append([detections])\n",
    "#             else:\n",
    "#                 ensemble_detections[i] += [detections]\n",
    "    \n",
    "#     for i in range(len(case_list)):\n",
    "#         ensemble_detections[i] = np.concatenate(ensemble_detections[i], axis=0)\n",
    "   \n",
    "#     false_positives = np.zeros((0,))\n",
    "#     true_positives = np.zeros((0,))\n",
    "#     scores = np.zeros((0,))\n",
    "#     num_annotations = 0.0\n",
    "    \n",
    "#     case_list = ensemble_case_list\n",
    "#     all_detections = ensemble_detections\n",
    "#     all_annotations = ensemble_annotations\n",
    "\n",
    "#     for i in range(len(case_list)):\n",
    "#         case = case_list[i]\n",
    "#         pid = '_'.join(case.split('_')[:-1])\n",
    "\n",
    "#         detections = all_detections[i]\n",
    "#         annotations = all_annotations[i]\n",
    "#         num_annotations += annotations.shape[0]\n",
    "#         detected_annotations = []\n",
    "\n",
    "#         bb_scores = torch.tensor(detections[:,4])\n",
    "#         anchorBoxes = torch.tensor(detections[:,:4])\n",
    "#         anchors_nms_idx = nms(anchorBoxes, bb_scores, NMS_IOU)\n",
    "#         anchors_nms_idx = anchors_nms_idx.numpy()\n",
    "#         detections = detections[anchors_nms_idx]\n",
    "\n",
    "#         for d in detections:\n",
    "#             if d[4] < S_IOU:\n",
    "#                 continue\n",
    "\n",
    "#             tmp_score = d[4]  * K_pid_score[str(k_idx)][pid]\n",
    "#             scores = np.append(scores, tmp_score)\n",
    "\n",
    "#             if annotations.shape[0] == 0:\n",
    "#                 false_positives = np.append(false_positives, 1)\n",
    "#                 true_positives = np.append(true_positives, 0)\n",
    "#                 continue\n",
    "\n",
    "#             d_tensor = torch.tensor(d[:4][np.newaxis])\n",
    "#             a_tensor = torch.tensor(annotations)\n",
    "#             overlaps = box_iou(d_tensor, a_tensor).numpy()\n",
    "#             assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "#             max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "#             if max_overlap >= H_IOU and assigned_annotation not in detected_annotations:\n",
    "#                 false_positives = np.append(false_positives, 0)\n",
    "#                 true_positives = np.append(true_positives, 1)\n",
    "#                 detected_annotations.append(assigned_annotation)\n",
    "#             else:\n",
    "#                 false_positives = np.append(false_positives, 1)\n",
    "#                 true_positives = np.append(true_positives, 0)\n",
    "\n",
    "#     if len(false_positives) == 0 and len(true_positives) == 0:\n",
    "#         print('No detection')\n",
    "#     else:\n",
    "#         # sort by score\n",
    "#         indices = np.argsort(-scores)\n",
    "#         scores = scores[indices]\n",
    "#         false_positives = false_positives[indices]\n",
    "#         true_positives = true_positives[indices]\n",
    "\n",
    "#         anno = num_annotations\n",
    "#         case_num = len(case_list)\n",
    "\n",
    "#         # compute false positives and true positives\n",
    "#         false_positives = np.cumsum(false_positives)\n",
    "#         true_positives = np.cumsum(true_positives)\n",
    "\n",
    "#         # compute recall and precision\n",
    "#         recall = true_positives / num_annotations\n",
    "#         precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "#         # compute average precision\n",
    "#         average_precision = compute_ap(recall, precision)\n",
    "\n",
    "#         print('mAP: {:.4f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a403e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7833 \n",
    "0.7628 \n",
    "0.8053 \n",
    "0.7887 \n",
    "0.8053 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7869 \n",
    "0.8029 \n",
    "0.7987 \n",
    "0.8123 \n",
    "0.8262 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b39af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5832c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
